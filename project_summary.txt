Project Structure & Python File Details for: Y:\Trading\Stock Selection

ğŸ§  Detected Data Access Points:
â€¢ aaa.py â†’ load_data('None', default)
â€¢ aaa.py â†’ load_data('None', default)
â€¢ agents/execution_agent_sql.py â†’ load_data('None', default)
â€¢ agents/memory_agent.py â†’ load_data('None', default)
â€¢ agents/memory_agent.py â†’ load_data('None', default)
â€¢ agents/memory_agent.py â†’ load_data('None', default)
â€¢ agents/planner_agent_sql.py â†’ load_data('None', default)
â€¢ agents/planner_agent_sql.py â†’ load_data('None', default)
â€¢ agents/planner_agent_sql.py â†’ load_data('None', default)
â€¢ agents/planner_agent_sql.py â†’ load_data('None', default)
â€¢ agents/planner_agent_sql.py â†’ load_data('None', default)
â€¢ agents/planner_agent_sql.py â†’ load_data('None', default)
â€¢ agents/planner_agent_sql.py â†’ load_data('None', default)
â€¢ agents/planner_agent_sql.py â†’ load_data('None', default)
â€¢ agents/planner_agent_sql.py â†’ load_data('None', default)
â€¢ agents/planner_agent_sql.py â†’ save_data('None', default)
â€¢ agents/strategy_agent.py â†’ load_data('None', default)
â€¢ agents/strategy_agent.py â†’ load_data('stock_price_history', default)
â€¢ agents/time_series_agent.py â†’ load_data('None', default)
â€¢ core/data_provider.py â†’ save_data('None', default)
â€¢ core/time_context.py â†’ load_data('stock_price_history', default)
â€¢ data_pipeline/zerodha_to_postgres.py â†’ load_data('None', default)
â€¢ data_pipeline/zerodha_to_postgres.py â†’ save_data('None', default)
â€¢ diagnosis/evaluate_model_curves.py â†’ load_data('None', default)
â€¢ diagnosis/evaluate_model_curves.py â†’ load_data('None', default)
â€¢ diagnosis/view_predicted_curves.py â†’ load_data('None', default)
â€¢ diagnosis/view_predicted_curves.py â†’ load_data('None', default)
â€¢ flows/auto_pipeline.py â†’ load_data('None', default)
â€¢ flows/auto_pipeline.py â†’ load_data('None', default)
â€¢ flows/auto_pipeline.py â†’ save_data('None', default)
â€¢ flows/fundamental_pipeline.py â†’ load_data('None', default)
â€¢ flows/fundamental_pipeline.py â†’ load_data('None', default)
â€¢ flows/fundamental_pipeline.py â†’ save_data('None', default)
â€¢ flows/trading_pipeline.py â†’ load_data('None', default)
â€¢ flows/trading_pipeline.py â†’ load_data('None', default)
â€¢ fundamentals/fundamental_data_extractor.py â†’ load_data('None', default)
â€¢ fundamentals/fundamental_data_extractor.py â†’ save_data('None', default)
â€¢ models/meta_strategy_selector.py â†’ save_data('None', default)
â€¢ models/ml_dual_model_prediction_sql.py â†’ load_data('None', default)
â€¢ models/ml_dual_model_prediction_sql.py â†’ load_data('None', default)
â€¢ models/ml_training_sql.py â†’ load_data('None', default)
â€¢ models/ml_training_sql.py â†’ save_data('None', default)
â€¢ models/stock_filter_predictor.py â†’ load_data('None', default)
â€¢ models/stock_filter_predictor.py â†’ save_data('None', default)
â€¢ models/train_dual_model_sql.py â†’ load_data('None', default)
â€¢ models/train_exit_model.py â†’ load_data('paper_trades', default)
â€¢ models/train_exit_model.py â†’ save_data('None', default)
â€¢ models/train_stock_filter_model.py â†’ load_data('training_data', default)
â€¢ predictive_trader/backtest_lstm_predictor.py â†’ load_data('stock_features', default)
â€¢ predictive_trader/curve_signal_generator.py â†’ load_data('None', default)
â€¢ predictive_trader/model_manager.py â†’ load_data('stock_price_history', default)
â€¢ predictive_trader/price_predictor_lgbm.py â†’ load_data('stock_price_history', default)
â€¢ predictive_trader/price_predictor_lstm.py â†’ load_data('stock_price_history', default)
â€¢ predictive_trader/price_predictor_lstm_v2.py â†’ load_data('stock_features', default)
â€¢ predictive_trader/price_predictor_lstm_v2.py â†’ load_data('stock_features', default)
â€¢ report_generator.py â†’ load_data('None', default)
â€¢ scripts/__archive__/execution_agent.py â†’ load_data('open_positions', default)
â€¢ scripts/__archive__/execution_agent.py â†’ load_data('recommendations', default)
â€¢ scripts/__archive__/execution_agent.py â†’ save_data('None', default)
â€¢ scripts/__archive__/planner_agent.py â†’ load_data('ml_selected_stocks', default)
â€¢ scripts/__archive__/planner_agent.py â†’ save_data('None', default)
â€¢ scripts/load_backup_fundamentals.py â†’ save_data('None', default)
â€¢ scripts/seed_training_data.py â†’ load_data('paper_trades', default)
â€¢ scripts/seed_training_data.py â†’ load_data('stock_features', default)
â€¢ scripts/seed_training_data.py â†’ save_data('None', default)
â€¢ services/feedback_loop.py â†’ load_data('None', default)
â€¢ services/feedback_loop.py â†’ load_data('None', default)
â€¢ services/feedback_loop.py â†’ save_data('None', default)
â€¢ stock_selecter/auto_filter_selector.py â†’ load_data('None', default)
â€¢ stock_selecter/fallback_technical_filter.py â†’ load_data('None', default)
â€¢ stock_selecter/fallback_technical_filter.py â†’ save_data('None', default)
â€¢ stock_selecter/stock_screener.py â†’ load_data('None', default)
â€¢ stock_selecter/stock_screener.py â†’ load_data('None', default)
â€¢ stock_selecter/stock_screener.py â†’ save_data('None', default)
â€¢ utils/precheck_features.py â†’ load_data('None', default)
â€¢ utils/precheck_features.py â†’ load_data('None', default)
â€¢ utils/stock_health_precheck.py â†’ load_data('None', default)

ğŸ“ Full Directory Summary with Code Info:
â””â”€â”€ Stock Selection
    ğŸ“„ Skipped 2 data files (.csv, .json, .pyc)
    â”œâ”€â”€ __pycache__/  [directory excluded]
    â”œâ”€â”€ aaa.py
    â”‚   Imports:
    â”‚     - core.config.settings
    â”‚     - core.data_provider.load_data
    â”‚     - core.time_context.get_simulation_date
    â”‚     - pandas
    â”œâ”€â”€ agents
    â”‚   â”œâ”€â”€ __pycache__/  [directory excluded]
    â”‚   â”œâ”€â”€ execution_agent_sql.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.data_provider.fetch_stock_data
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - datetime.datetime
    â”‚   â”‚     - db.conflict_utils.insert_with_conflict_handling
    â”‚   â”‚     - db.postgres_manager.run_query
    â”‚   â”‚     - os
    â”‚   â”‚     - pandas
    â”‚   â”‚     - time
    â”‚   â”‚   Class: ExecutionAgentSQL
    â”‚   â”‚     Methods:
    â”‚   â”‚       - __init__
    â”‚   â”‚       - load_signals
    â”‚   â”‚       - load_open_positions
    â”‚   â”‚       - load_today_ohlc
    â”‚   â”‚       - exit_trades
    â”‚   â”‚       - enter_trades
    â”‚   â”‚       - run
    â”‚   â”‚   Function: safe_load_table
    â”‚   â”œâ”€â”€ memory_agent.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.model_io.save_model
    â”‚   â”‚     - core.time_context.get_simulation_date
    â”‚   â”‚     - datetime.datetime
    â”‚   â”‚     - db.conflict_utils.insert_with_conflict_handling
    â”‚   â”‚     - db.postgres_manager.run_query
    â”‚   â”‚     - models.meta_strategy_selector.train_meta_model
    â”‚   â”‚     - models.train_dual_model_sql.train_dual_model
    â”‚   â”‚     - models.train_exit_model.train_exit_model
    â”‚   â”‚     - models.train_stock_filter_model.train_stock_filter_model
    â”‚   â”‚     - pandas
    â”‚   â”‚     - pandas.tseries.offsets.BDay
    â”‚   â”‚   Class: MemoryAgent
    â”‚   â”‚     Methods:
    â”‚   â”‚       - __init__
    â”‚   â”‚       - archive_table
    â”‚   â”‚       - summarize_weekly_performance
    â”‚   â”‚       - check_retraining_needed
    â”‚   â”‚       - feedback_loop
    â”‚   â”‚         Docstring:
    â”‚   â”‚         Merge features with today's trades (using previous business-
    â”‚   â”‚         day features) and upsert into training_data.
    â”‚   â”‚       - update
    â”‚   â”œâ”€â”€ planner_agent_sql.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - agents.execution_agent_sql.ExecutionAgentSQL
    â”‚   â”‚     - agents.memory_agent.MemoryAgent
    â”‚   â”‚     - agents.risk_management_agent.RiskManagementAgent
    â”‚   â”‚     - agents.signal_arbitration_agent.SignalArbitrationAgent
    â”‚   â”‚     - agents.strategy_agent.StrategyAgent
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.data_provider.fetch_stock_data
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.time_context.get_simulation_date
    â”‚   â”‚     - datetime.datetime
    â”‚   â”‚     - db.conflict_utils.insert_with_conflict_handling
    â”‚   â”‚     - db.db.SessionLocal
    â”‚   â”‚     - db.db.engine
    â”‚   â”‚     - db.models.Base
    â”‚   â”‚     - db.postgres_manager.run_query
    â”‚   â”‚     - fundamentals.fundamental_data_extractor
    â”‚   â”‚     - numpy
    â”‚   â”‚     - pandas
    â”‚   â”‚     - random
    â”‚   â”‚     - sqlalchemy.text
    â”‚   â”‚     - stock_selecter.auto_filter_selector.auto_select_filter
    â”‚   â”‚     - tqdm.tqdm
    â”‚   â”‚     - warnings
    â”‚   â”‚   Class: PlannerAgentSQL
    â”‚   â”‚     Methods:
    â”‚   â”‚       - __init__
    â”‚   â”‚       - run_weekly_routine
    â”‚   â”‚       - _fetch_fundamentals
    â”‚   â”‚       - _fetch_price_history
    â”‚   â”‚       - _refresh_features
    â”‚   â”‚       - _filter_stocks
    â”‚   â”‚       - _evaluate_stocks
    â”‚   â”‚       - _execute_trades
    â”‚   â”‚       - _update_systems
    â”‚   â”œâ”€â”€ portfolio_allocator.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.data_provider.save_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - pandas
    â”‚   â”‚   Class: PortfolioAllocatorAgent
    â”‚   â”‚     Methods:
    â”‚   â”‚       - __init__
    â”‚   â”‚       - allocate
    â”‚   â”œâ”€â”€ risk_management_agent.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - pandas
    â”‚   â”‚   Class: RiskManagementAgent
    â”‚   â”‚     Methods:
    â”‚   â”‚       - __init__
    â”‚   â”‚       - apply_risk_controls
    â”‚   â”œâ”€â”€ signal_arbitration_agent.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - numpy
    â”‚   â”‚   Class: SignalArbitrationAgent
    â”‚   â”‚     Methods:
    â”‚   â”‚       - __init__
    â”‚   â”‚       - arbitrate
    â”‚   â”œâ”€â”€ strategy_agent.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - agents.time_series_agent.TimeSeriesAgent
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.grid_predictor.predict_grid_config
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.model_io.load_model
    â”‚   â”‚     - core.predictor.predict_dual_model
    â”‚   â”‚     - core.skiplist.add_to_skiplist
    â”‚   â”‚     - datetime.datetime
    â”‚   â”‚     - db.db.SessionLocal
    â”‚   â”‚     - db.models.ParamModelPrediction
    â”‚   â”‚     - db.models.StockFeature
    â”‚   â”‚     - pandas
    â”‚   â”‚     - random
    â”‚   â”‚     - sqlalchemy.orm.Session
    â”‚   â”‚     - traceback
    â”‚   â”‚   Class: StrategyAgent
    â”‚   â”‚     Methods:
    â”‚   â”‚       - __init__
    â”‚   â”‚       - fetch_features
    â”‚   â”‚       - evaluate
    â”‚   â”‚       - _handle_grid_fallback
    â”‚   â”‚       - log_summary
    â”‚   â”‚   Function: is_valid_for_model
    â”‚   â””â”€â”€ time_series_agent.py
    â”‚       Imports:
    â”‚         - core.config.settings
    â”‚         - core.data_provider.load_data
    â”‚         - core.logger.logger
    â”‚         - core.model_io.load_model
    â”‚         - core.model_io.save_model
    â”‚         - datetime.timedelta
    â”‚         - numpy
    â”‚         - pandas
    â”‚         - pmdarima.arima.ARIMA
    â”‚         - traceback
    â”‚         - warnings
    â”‚       Class: TimeSeriesAgent
    â”‚         Methods:
    â”‚           - __init__
    â”‚           - _get_hist
    â”‚           - train_and_store
    â”‚           - predict
    â”‚       Function: warning_to_log
    â”œâ”€â”€ cache
    â”‚   ğŸ“„ Skipped 1 data files (.csv, .json, .pyc)
    â”‚   â””â”€â”€ fundamentals
    â”œâ”€â”€ config
    â”‚   ğŸ“„ Skipped 1 data files (.csv, .json, .pyc)
    â”‚   â”œâ”€â”€ __pycache__/  [directory excluded]
    â”‚   â”œâ”€â”€ paths.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - pathlib.Path
    â”‚   â”œâ”€â”€ postgres_config.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - os
    â”‚   â”‚   Function: get_pg_conn_params
    â”‚   â”œâ”€â”€ sql_tables.py
    â”‚   â””â”€â”€ system_config.py
    â”œâ”€â”€ core
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ __pycache__/  [directory excluded]
    â”‚   â”œâ”€â”€ backtest_bt.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - backtesting.Backtest
    â”‚   â”‚     - backtesting.Strategy
    â”‚   â”‚     - backtesting.lib.crossover
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.data_provider.fetch_stock_data
    â”‚   â”‚     - pandas
    â”‚   â”‚   Class: SMA_RSI
    â”‚   â”‚     Docstring:
    â”‚   â”‚     SMA crossover entry with RSIâ€based exit.
    â”‚   â”‚     Methods:
    â”‚   â”‚       - init
    â”‚   â”‚       - next
    â”‚   â”‚   Function: ta_sma
    â”‚   â”‚   Function: ta_rsi
    â”‚   â”‚   Function: run_backtest
    â”‚   â”‚     Docstring:
    â”‚   â”‚     Fetch OHLCV data, run the SMA_RSI strategy, and return
    â”‚   â”‚     performance stats.
    â”‚   â”œâ”€â”€ config.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - pathlib.Path
    â”‚   â”‚     - pydantic.BaseModel
    â”‚   â”‚     - pydantic.Field
    â”‚   â”‚     - pydantic.SecretStr
    â”‚   â”‚     - pydantic_settings.BaseSettings
    â”‚   â”‚     - typing.ClassVar
    â”‚   â”‚     - typing.Dict
    â”‚   â”‚     - typing.List
    â”‚   â”‚     - typing.Optional
    â”‚   â”‚     - typing.Tuple
    â”‚   â”‚   Class: RetrainConfig
    â”‚   â”‚   Class: Settings
    â”‚   â”‚   Class: Config
    â”‚   â”œâ”€â”€ data_cleaner.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - pandas
    â”‚   â”‚   Function: normalize_columns
    â”‚   â”‚   Function: sanity_check_features
    â”‚   â”œâ”€â”€ data_initializer.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.data_provider.fetch_stock_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - db.conflict_utils.insert_with_conflict_handling
    â”‚   â”‚     - db.postgres_manager.read_table
    â”‚   â”‚     - integrations.zerodha_fetcher.fetch_historical_data
    â”‚   â”‚     - os
    â”‚   â”‚     - pandas
    â”‚   â”‚   Function: ensure_price_history_prefilled
    â”‚   â”‚     Docstring:
    â”‚   â”‚     Ensures price history is populated in SQL for selected
    â”‚   â”‚     stocks in stock_fundamentals. Uses whitelist if provided.
    â”‚   â”‚     Skips if enough data is already present.
    â”‚   â”œâ”€â”€ data_provider.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - datetime.datetime
    â”‚   â”‚     - db.conflict_utils.insert_with_conflict_handling
    â”‚   â”‚     - db.db.SessionLocal
    â”‚   â”‚     - db.models.Instrument
    â”‚   â”‚     - db.models.MLSelectedStock
    â”‚   â”‚     - db.models.OpenPosition
    â”‚   â”‚     - db.models.PaperTrade
    â”‚   â”‚     - db.models.Recommendation
    â”‚   â”‚     - db.models.SkiplistStock
    â”‚   â”‚     - db.models.StockEncoding
    â”‚   â”‚     - db.models.StockFeature
    â”‚   â”‚     - db.models.StockFundamental
    â”‚   â”‚     - db.models.StockPriceHistory
    â”‚   â”‚     - integrations.zerodha_fetcher.fetch_historical_data
    â”‚   â”‚     - pandas
    â”‚   â”‚     - typing.Any
    â”‚   â”‚     - typing.List
    â”‚   â”‚     - typing.Optional
    â”‚   â”‚   Function: load_data
    â”‚   â”‚   Function: save_data
    â”‚   â”‚   Function: fetch_stock_data
    â”‚   â”‚   Function: get_last_close
    â”‚   â”‚   Function: delete_cached_features
    â”‚   â”‚   Function: list_partitions
    â”‚   â”œâ”€â”€ grid_predictor.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - backtesting.Backtest
    â”‚   â”‚     - backtesting.backtesting
    â”‚   â”‚     - core.backtest_bt.SMA_RSI
    â”‚   â”‚     - core.data_provider.fetch_stock_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.time_context.get_simulation_date
    â”‚   â”‚     - datetime.datetime
    â”‚   â”‚     - db.postgres_manager.run_query
    â”‚   â”‚     - multiprocessing
    â”‚   â”‚   Function: predict_grid_config
    â”‚   â”‚   Function: persist_grid_recommendations
    â”‚   â”œâ”€â”€ logger.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - datetime.datetime
    â”‚   â”‚     - logging
    â”‚   â”‚     - os
    â”‚   â”‚     - sys
    â”‚   â”‚   Class: SafeFormatter
    â”‚   â”‚     Methods:
    â”‚   â”‚       - format
    â”‚   â”‚   Function: success
    â”‚   â”‚   Function: warn
    â”‚   â”‚   Function: error
    â”‚   â”‚   Function: start
    â”‚   â”œâ”€â”€ model_io.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - datetime.datetime
    â”‚   â”‚     - db.conflict_utils.insert_with_conflict_handling
    â”‚   â”‚     - db.postgres_manager.run_query
    â”‚   â”‚     - pandas
    â”‚   â”‚     - pickle
    â”‚   â”‚   Function: save_model
    â”‚   â”‚     Docstring:
    â”‚   â”‚     Serialize and save a model to the configured SQL table using
    â”‚   â”‚     conflict handling.
    â”‚   â”‚   Function: load_model
    â”‚   â”‚     Docstring:
    â”‚   â”‚     Load a model from the configured SQL table.
    â”‚   â”œâ”€â”€ predictor.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - agents.signal_arbitration_agent.SignalArbitrationAgent
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.model_io.load_model
    â”‚   â”‚     - core.time_context.get_simulation_date
    â”‚   â”‚     - db.conflict_utils.insert_with_conflict_handling
    â”‚   â”‚     - models.ml_dual_model_prediction_sql.predict_dual_model
    â”‚   â”‚     - pandas
    â”‚   â”‚   Function: predict_dual_model
    â”‚   â”‚     Docstring:
    â”‚   â”‚     Predicts if a trade should be triggered and its expected
    â”‚   â”‚     return.  Returns a list of dicts:   [{      "stock":
    â”‚   â”‚     <symbol>,      "trade_triggered": <0|1>,
    â”‚   â”‚     "predicted_return": <float>,      "recommended_config":
    â”‚   â”‚     <dict of feature:value>   }]
    â”‚   â”œâ”€â”€ skiplist.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - db.postgres_manager.run_query
    â”‚   â”‚   Function: is_in_skiplist
    â”‚   â”‚   Function: add_to_skiplist
    â”‚   â”‚   Function: remove_from_skiplist
    â”‚   â”œâ”€â”€ time_context.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - datetime.datetime
    â”‚   â”‚     - os
    â”‚   â”‚     - pandas
    â”‚   â”‚     - pandas.tseries.offsets.BDay
    â”‚   â”‚   Function: get_simulation_date
    â”‚   â”‚     Docstring:
    â”‚   â”‚     Return SIMULATED_DATE from env or fallback to latest
    â”‚   â”‚     available date in price history.
    â”‚   â”‚   Function: set_simulation_date
    â”‚   â”‚   Function: clear_simulation_date
    â”‚   â”œâ”€â”€ token_manager.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - json
    â”‚   â”‚     - os
    â”‚   â”‚     - pathlib.Path
    â”‚   â”‚   Function: save_access_token
    â”‚   â”‚   Function: load_access_token
    â”‚   â”‚   Function: get_saved_access_token
    â”‚   â””â”€â”€ validation
    â”‚       â”œâ”€â”€ __init__.py
    â”‚       â”œâ”€â”€ __pycache__/  [directory excluded]
    â”‚       â””â”€â”€ data_checks.py
    â”‚           Imports:
    â”‚             - numpy
    â”‚             - pandas
    â”‚             - scipy.stats.zscore
    â”‚           Function: check_missing
    â”‚           Function: class_balance
    â”‚           Function: detect_outliers
    â”œâ”€â”€ create_daily_features.sql
    â”œâ”€â”€ data
    â”‚   ğŸ“„ Skipped 1 data files (.csv, .json, .pyc)
    â”œâ”€â”€ data_pipeline
    â”‚   â”œâ”€â”€ __pycache__/  [directory excluded]
    â”‚   â””â”€â”€ zerodha_to_postgres.py
    â”‚       Imports:
    â”‚         - core.data_provider.load_data
    â”‚         - core.data_provider.save_data
    â”‚         - core.logger.logger
    â”‚         - datetime.datetime
    â”‚         - datetime.timedelta
    â”‚         - db.postgres_manager.run_query
    â”‚         - integrations.zerodha_fetcher.fetch_historical_data
    â”‚         - os
    â”‚         - pandas
    â”‚         - time
    â”‚       Function: load_stock_list
    â”‚       Function: fetch_and_save_stock
    â”‚       Function: main
    â”œâ”€â”€ db
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ __pycache__/  [directory excluded]
    â”‚   â”œâ”€â”€ conflict_utils.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - db.db.engine
    â”‚   â”‚     - db.models.Base
    â”‚   â”‚     - pandas
    â”‚   â”‚     - sqlalchemy.dialects.postgresql.insert
    â”‚   â”‚   Function: insert_with_conflict_handling
    â”‚   â”‚     Docstring:
    â”‚   â”‚     Bulk insert DataFrame into Postgres with ON CONFLICT
    â”‚   â”‚     handling via SQLAlchemy Core.
    â”‚   â”œâ”€â”€ csv_to_sql.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - db.db_router.insert_dataframe
    â”‚   â”‚     - pandas
    â”‚   â”‚     - pathlib.Path
    â”‚   â”‚     - sys
    â”‚   â”‚   Function: csv_to_sql
    â”‚   â”œâ”€â”€ db.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - config.postgres_config.get_pg_conn_params
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - sqlalchemy.create_engine
    â”‚   â”‚     - sqlalchemy.orm.sessionmaker
    â”‚   â”‚   Function: get_session
    â”‚   â”‚     Docstring:
    â”‚   â”‚     Returns a new SQLAlchemy Session. Usage:     with
    â”‚   â”‚     get_session() as session:         ...
    â”‚   â”œâ”€â”€ db_manager.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - config.paths.PATHS
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - pandas
    â”‚   â”‚     - sqlite3
    â”‚   â”‚     - time
    â”‚   â”‚   Function: get_connection
    â”‚   â”‚     Docstring:
    â”‚   â”‚     Block until connection is possible and WAL is enabled.
    â”‚   â”‚   Function: insert_dataframe
    â”‚   â”‚   Function: read_table
    â”‚   â”‚   Function: run_query
    â”‚   â”‚   Function: list_tables
    â”‚   â”‚   Function: execute_raw_sql
    â”‚   â”‚   Function: enable_wal_mode
    â”‚   â”œâ”€â”€ init_postgres.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - db.postgres_manager.execute_raw_sql
    â”‚   â”‚     - db.postgres_manager.run_query
    â”‚   â”‚   Function: table_exists
    â”‚   â”‚   Function: init_postgres
    â”‚   â”œâ”€â”€ models.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - datetime.date
    â”‚   â”‚     - datetime.datetime
    â”‚   â”‚     - sqlalchemy.BigInteger
    â”‚   â”‚     - sqlalchemy.Boolean
    â”‚   â”‚     - sqlalchemy.Column
    â”‚   â”‚     - sqlalchemy.Date
    â”‚   â”‚     - sqlalchemy.DateTime
    â”‚   â”‚     - sqlalchemy.Float
    â”‚   â”‚     - sqlalchemy.Integer
    â”‚   â”‚     - sqlalchemy.String
    â”‚   â”‚     - sqlalchemy.orm.declarative_base
    â”‚   â”‚   Class: Instrument
    â”‚   â”‚   Class: SkiplistStock
    â”‚   â”‚   Class: StockPriceHistory
    â”‚   â”‚   Class: StockFeature
    â”‚   â”‚   Class: StockFundamental
    â”‚   â”‚   Class: StockEncoding
    â”‚   â”‚   Class: Recommendation
    â”‚   â”‚   Class: OpenPosition
    â”‚   â”‚   Class: PaperTrade
    â”‚   â”‚   Class: FilterModelPrediction
    â”‚   â”‚   Class: ParamModelPrediction
    â”‚   â”‚   Class: PriceModelPrediction
    â”‚   â”‚   Class: MLSelectedStock
    â”‚   â”‚     Methods:
    â”‚   â”‚       - __repr__
    â”‚   â””â”€â”€ postgres_manager.py
    â”‚       Imports:
    â”‚         - config.postgres_config.get_pg_conn_params
    â”‚         - pandas
    â”‚         - sqlalchemy.create_engine
    â”‚         - sqlalchemy.text
    â”‚       Function: get_engine
    â”‚       Function: read_table
    â”‚       Function: run_query
    â”‚       Function: execute_raw_sql
    â”‚       Function: insert_dataframe
    â”‚         Docstring:
    â”‚         Bulk-insert a DataFrame into a PostgreSQL table using
    â”‚         SQLAlchemy.
    â”œâ”€â”€ diagnosis
    â”‚   â”œâ”€â”€ __pycache__/  [directory excluded]
    â”‚   â”œâ”€â”€ clear_all_sql_tables.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - db.db_router.execute_raw_sql
    â”‚   â”‚   Function: clear_all_tables
    â”‚   â”œâ”€â”€ diagnose_storage.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - os
    â”‚   â”‚     - pathlib.Path
    â”‚   â”‚     - sqlite3
    â”‚   â”‚   Function: table_exists
    â”‚   â”œâ”€â”€ evaluate_model_curves.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - matplotlib.pyplot
    â”‚   â”‚     - numpy
    â”‚   â”‚     - pandas
    â”‚   â”‚     - sklearn.metrics.mean_absolute_error
    â”‚   â”‚     - sklearn.metrics.mean_squared_error
    â”‚   â”‚   Function: load_predictions
    â”‚   â”‚   Function: load_actual_prices
    â”‚   â”‚   Function: evaluate_model
    â”‚   â”œâ”€â”€ fix_model_path_usage.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - pathlib.Path
    â”‚   â”‚     - re
    â”‚   â”‚   Function: fix_file
    â”‚   â”‚   Function: main
    â”‚   â”œâ”€â”€ migrate_paths_to_sql.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - argparse
    â”‚   â”‚     - os
    â”‚   â”‚     - pathlib.Path
    â”‚   â”‚     - re
    â”‚   â”‚   Function: transform_code
    â”‚   â”‚   Function: update_file
    â”‚   â”‚   Function: run_all
    â”‚   â”œâ”€â”€ migrate_to_sql.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - config.paths.PATHS
    â”‚   â”‚     - db.db_router.DB_PATH
    â”‚   â”‚     - db.db_router.insert_dataframe
    â”‚   â”‚     - os
    â”‚   â”‚     - pandas
    â”‚   â”‚     - pickle
    â”‚   â”‚     - sqlite3
    â”‚   â”‚   Function: ensure_blob_json_tables
    â”‚   â”‚     Docstring:
    â”‚   â”‚     Create the blob and JSON store tables if they don't exist.
    â”‚   â”‚   Function: migrate_csv
    â”‚   â”‚   Function: migrate_pkl
    â”‚   â”‚   Function: migrate_json
    â”‚   â”‚   Function: migrate_to_sql
    â”‚   â”œâ”€â”€ seed_training_data.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - db.db_router.insert_dataframe
    â”‚   â”‚     - pandas
    â”‚   â”‚   Function: seed
    â”‚   â”œâ”€â”€ simulate_execution.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - agents.execution_agent_sql.ExecutionAgentSQL
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.time_context.clear_simulation_date
    â”‚   â”‚     - core.time_context.set_simulation_date
    â”‚   â”‚     - datetime.datetime
    â”‚   â”‚     - datetime.timedelta
    â”‚   â”‚     - predictive_trader.curve_predictor.generate_curves_for_list
    â”‚   â”‚     - predictive_trader.curve_signal_generator.generate_signals_from_curves
    â”‚   â”‚   Function: generate_trading_days
    â”‚   â”‚   Function: simulate_trading_days
    â”‚   â”œâ”€â”€ simulate_history.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - agents.planner_agent_sql.PlannerAgentSQL
    â”‚   â”‚     - argparse
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.time_context.set_simulation_date
    â”‚   â”‚     - datetime.datetime
    â”‚   â”‚     - datetime.timedelta
    â”‚   â”‚     - logging
    â”‚   â”‚     - os
    â”‚   â”‚   Function: daterange
    â”‚   â”‚     Docstring:
    â”‚   â”‚     Yield one date per week between start and end.
    â”‚   â”‚   Function: parse_args
    â”‚   â”‚   Function: main
    â”‚   â”œâ”€â”€ simulate_history_single.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - agents.planner_agent_sql.PlannerAgentSQL
    â”‚   â”‚     - argparse
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.time_context.set_simulation_date
    â”‚   â”‚     - datetime.datetime
    â”‚   â”‚     - datetime.timedelta
    â”‚   â”‚     - pandas
    â”‚   â”‚   Function: simulate_stock_over_range
    â”‚   â””â”€â”€ view_predicted_curves.py
    â”‚       Imports:
    â”‚         - core.data_provider.load_data
    â”‚         - core.logger.logger
    â”‚         - matplotlib.pyplot
    â”‚         - numpy
    â”‚         - pandas
    â”‚         - sklearn.metrics.mean_absolute_error
    â”‚         - sklearn.metrics.mean_squared_error
    â”‚       Function: load_predictions
    â”‚       Function: load_actual_prices
    â”‚       Function: evaluate_model
    â”œâ”€â”€ flows
    â”‚   â”œâ”€â”€ __pycache__/  [directory excluded]
    â”‚   â”œâ”€â”€ auto_pipeline.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - agents.memory_agent.MemoryAgent
    â”‚   â”‚     - archive.feature_enricher.enrich_features
    â”‚   â”‚     - argparse
    â”‚   â”‚     - core.backtest_bt.run_backtest
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.data_provider.fetch_stock_data
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.data_provider.save_data
    â”‚   â”‚     - datetime.date
    â”‚   â”‚     - datetime.timedelta
    â”‚   â”‚     - db.db.get_session
    â”‚   â”‚     - models.meta_strategy_selector.train_meta_model
    â”‚   â”‚     - models.stock_filter_predictor.run_stock_filter
    â”‚   â”‚     - models.train_dual_model_sql.train_dual_model
    â”‚   â”‚     - models.train_stock_filter_model.train_stock_filter_model
    â”‚   â”‚     - prefect.flow
    â”‚   â”‚     - prefect.get_run_logger
    â”‚   â”‚     - prefect.server.schemas.schedules.IntervalSchedule
    â”‚   â”‚     - prefect.task
    â”‚   â”‚     - services.feedback_loop.update_training_data
    â”‚   â”‚     - sqlalchemy.text
    â”‚   â”‚   Function: get_last_date
    â”‚   â”‚   Function: update_last_date
    â”‚   â”‚   Function: ingest_data
    â”‚   â”‚   Function: enrich
    â”‚   â”‚   Function: run_filter
    â”‚   â”‚   Function: backtest_and_label
    â”‚   â”‚   Function: check_drift_and_trigger
    â”‚   â”‚   Function: retrain_models
    â”‚   â”‚   Function: self_learning_pipeline
    â”‚   â”œâ”€â”€ backfill_pipeline.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - argparse
    â”‚   â”‚     - datetime.date
    â”‚   â”‚     - datetime.timedelta
    â”‚   â”‚     - flows.auto_pipeline.self_learning_pipeline
    â”‚   â”‚     - prefect.flow
    â”‚   â”‚   Function: historical_backfill
    â”‚   â”œâ”€â”€ fundamental_pipeline.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - argparse
    â”‚   â”‚     - bs4.BeautifulSoup
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.data_provider.save_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.skiplist.add_to_skiplist
    â”‚   â”‚     - core.skiplist.is_in_skiplist
    â”‚   â”‚     - db.postgres_manager.run_query
    â”‚   â”‚     - numpy
    â”‚   â”‚     - os
    â”‚   â”‚     - pandas
    â”‚   â”‚     - pathlib.Path
    â”‚   â”‚     - prefect.flow
    â”‚   â”‚     - prefect.get_run_logger
    â”‚   â”‚     - prefect.task
    â”‚   â”‚     - requests
    â”‚   â”‚     - time
    â”‚   â”‚     - yfinance
    â”‚   â”‚   Function: load_nse_symbols
    â”‚   â”‚   Function: is_cache_valid
    â”‚   â”‚   Function: save_local_cache
    â”‚   â”‚   Function: clear_sql_table
    â”‚   â”‚   Function: clear_local_cache
    â”‚   â”‚   Function: _scrape_screener
    â”‚   â”‚   Function: _fetch_yfinance
    â”‚   â”‚   Function: fetch_fundamentals
    â”‚   â”‚   Function: parse_fundamentals
    â”‚   â”‚   Function: clear_everything
    â”‚   â”‚   Function: get_todo_symbols
    â”‚   â”‚   Function: fetch_one
    â”‚   â”‚   Function: save_batch
    â”‚   â”‚   Function: fundamental_fetch_flow
    â”‚   â”‚     Docstring:
    â”‚   â”‚     1) Optionally clear out everything if --force 2) Figure out
    â”‚   â”‚     which symbols still need data 3) Fan out one task per symbol
    â”‚   â”‚     (up to your concurrency limit) 4) Persist the successful
    â”‚   â”‚     rows back into SQL 5) On subsequent Prefect runs youâ€™ll only
    â”‚   â”‚     fetch the delta    until â€œget_todo_symbolsâ€ returns empty â†’
    â”‚   â”‚     youâ€™re done.
    â”‚   â””â”€â”€ trading_pipeline.py
    â”‚       Imports:
    â”‚         - core.data_provider.load_data
    â”‚         - datetime.date
    â”‚         - db.postgres_manager.run_query
    â”‚         - optuna
    â”‚         - pandas
    â”‚         - prefect.deployments.Deployment
    â”‚         - prefect.flow
    â”‚         - prefect.server.schemas.schedules.CronSchedule
    â”‚         - prefect.task
    â”‚         - vectorbt
    â”‚       Class: FeatureBuilder
    â”‚         Methods:
    â”‚           - __init__
    â”‚           - build
    â”‚       Class: SignalGenerator
    â”‚         Methods:
    â”‚           - __init__
    â”‚           - generate
    â”‚       Function: task_fetch_price
    â”‚       Function: task_persist_signals
    â”‚       Function: task_execute
    â”‚       Function: optimize_strategy
    â”‚       Function: daily_trading_flow
    â”‚       Function: objective
    â”œâ”€â”€ fundamentals
    â”‚   ğŸ“„ Skipped 2 data files (.csv, .json, .pyc)
    â”‚   â”œâ”€â”€ __pycache__/  [directory excluded]
    â”‚   â””â”€â”€ fundamental_data_extractor.py
    â”‚       Imports:
    â”‚         - core.data_provider.load_data
    â”‚         - core.data_provider.save_data
    â”‚         - core.logger.logger
    â”‚         - pandas
    â”‚       Function: load_backup_and_save
    â”‚       Function: fetch_all
    â”œâ”€â”€ generate_project_summary.py
    â”‚   Imports:
    â”‚     - argparse
    â”‚     - ast
    â”‚     - core.logger.logger
    â”‚     - os
    â”‚     - textwrap
    â”‚   Function: parse_python_file
    â”‚   Function: attach_parents
    â”‚   Function: extract_data_access_summary
    â”‚   Function: build_tree_and_extract
    â”‚   Function: main
    â”‚   Function: parse_with_parent
    â”œâ”€â”€ generate_stock_labels.py
    â”‚   Imports:
    â”‚     - core.logger.logger
    â”‚     - os
    â”‚     - pandas
    â”‚   Function: generate_labels
    â”œâ”€â”€ generate_training_data.py
    â”‚   Imports:
    â”‚     - core.logger.logger
    â”‚     - os
    â”‚     - pandas
    â”‚   Function: main
    â”œâ”€â”€ hpo.py
    â”‚   Imports:
    â”‚     - models.meta_strategy_selector.train_meta_model
    â”‚     - models.train_dual_model_sql.train_dual_model
    â”‚     - models.train_stock_filter_model.train_stock_filter_model
    â”œâ”€â”€ integrations
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ __pycache__/  [directory excluded]
    â”‚   â”œâ”€â”€ drift_detection.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - evidently.metric_preset.DataDriftPreset
    â”‚   â”‚     - evidently.report.Report
    â”‚   â”‚   Function: check_drift
    â”‚   â”œâ”€â”€ zerodha_client.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - json
    â”‚   â”‚     - kiteconnect.KiteConnect
    â”‚   â”‚     - kiteconnect.KiteTicker
    â”‚   â”‚     - os
    â”‚   â”‚   Function: get_kite
    â”‚   â”‚   Function: get_ticker
    â”‚   â””â”€â”€ zerodha_fetcher.py
    â”‚       Imports:
    â”‚         - core.logger.logger
    â”‚         - datetime.datetime
    â”‚         - datetime.timedelta
    â”‚         - dateutil.parser.parse
    â”‚         - db.conflict_utils.insert_with_conflict_handling
    â”‚         - integrations.zerodha_client.get_kite
    â”‚         - os
    â”‚         - pandas
    â”‚       Function: get_last_trading_day
    â”‚       Function: is_valid_price_df
    â”‚       Function: fetch_historical_data
    â”‚       Function: get_instrument_token
    â”‚       Function: main
    â”œâ”€â”€ logs
    â”‚   ğŸ“„ Skipped 1 data files (.csv, .json, .pyc)
    â”‚   â”œâ”€â”€ history_simulation
    â”‚   â”‚   â””â”€â”€ simulate_history_20250503_111707.log
    â”‚   â”œâ”€â”€ planner_agent_20250518_181633.log
    â”‚   â”œâ”€â”€ planner_agent_20250518_182621.log
    â”‚   â”œâ”€â”€ planner_agent_20250518_183449.log
    â”‚   â”œâ”€â”€ planner_agent_20250518_184724.log
    â”‚   â”œâ”€â”€ planner_agent_20250518_211106.log
    â”‚   â””â”€â”€ planner_agent_20250518_211321.log
    â”œâ”€â”€ models
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ __pycache__/  [directory excluded]
    â”‚   â”œâ”€â”€ meta_strategy_selector.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.data_provider.save_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.model_io.load_model
    â”‚   â”‚     - core.model_io.save_model
    â”‚   â”‚     - itertools
    â”‚   â”‚     - pandas
    â”‚   â”‚     - sklearn.ensemble.RandomForestRegressor
    â”‚   â”‚     - sklearn.metrics.mean_squared_error
    â”‚   â”‚     - sklearn.model_selection.train_test_split
    â”‚   â”‚   Function: load_combined_grid_data
    â”‚   â”‚     Docstring:
    â”‚   â”‚     Load and combine grid search results from all configured CSV
    â”‚   â”‚     paths.
    â”‚   â”‚   Function: train_meta_model
    â”‚   â”‚     Docstring:
    â”‚   â”‚     Train a meta-model to predict strategy performance. Reads
    â”‚   â”‚     combined grid data, applies settings-driven train/test
    â”‚   â”‚     split, trains an RF regressor with settings-backed
    â”‚   â”‚     hyperparams, logs & saves the model and its metadata.
    â”‚   â”‚   Function: suggest_best_parameters
    â”‚   â”‚     Docstring:
    â”‚   â”‚     Given a trained meta-model, enumerate the cartesian product
    â”‚   â”‚     of settings-backed parameter ranges, predict their score,
    â”‚   â”‚     and return the top-N configs as a DataFrame.
    â”‚   â”œâ”€â”€ ml_dual_model_prediction_sql.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.model_io.load_model
    â”‚   â”‚     - core.time_context.get_simulation_date
    â”‚   â”‚     - pandas
    â”‚   â”‚   Function: predict_dual_model
    â”‚   â”‚     Docstring:
    â”‚   â”‚     Dualâ€model prediction pipeline: - Loads fundamentals from
    â”‚   â”‚     `data_path` - Loads feature table from `feature_path` - Runs
    â”‚   â”‚     filter and exit models, returns top_n signals
    â”‚   â”œâ”€â”€ ml_training_sql.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.data_provider.save_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.model_io.save_model
    â”‚   â”‚     - pandas
    â”‚   â”‚     - sklearn.ensemble.RandomForestRegressor
    â”‚   â”‚     - sklearn.metrics.mean_squared_error
    â”‚   â”‚     - sklearn.model_selection.train_test_split
    â”‚   â”‚     - sklearn.preprocessing.LabelEncoder
    â”‚   â”‚   Function: train_meta_model
    â”‚   â”‚     Docstring:
    â”‚   â”‚     Train a meta-model (regressor) on combined features. Uses
    â”‚   â”‚     settings for split and hyperparams.
    â”‚   â”œâ”€â”€ predictive_trader
    â”‚   â”‚   â”œâ”€â”€ RELIANCE_v2_lstm.keras
    â”‚   â”‚   â””â”€â”€ RELIANCE_v2_scaler.pkl
    â”‚   â”œâ”€â”€ stock_filter_predictor.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.data_provider.save_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.model_io.load_model
    â”‚   â”‚     - pandas
    â”‚   â”‚   Function: run_stock_filter
    â”‚   â”œâ”€â”€ train_dual_model_sql.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.model_io.load_model
    â”‚   â”‚     - core.model_io.save_model
    â”‚   â”‚     - optuna
    â”‚   â”‚     - pandas
    â”‚   â”‚     - sklearn.ensemble.RandomForestClassifier
    â”‚   â”‚     - sklearn.ensemble.RandomForestRegressor
    â”‚   â”‚     - sklearn.metrics.accuracy_score
    â”‚   â”‚     - sklearn.metrics.mean_squared_error
    â”‚   â”‚     - sklearn.model_selection.train_test_split
    â”‚   â”‚   Function: _load_training
    â”‚   â”‚   Function: train_dual_model
    â”‚   â”‚   Function: objective_class
    â”‚   â”‚   Function: objective_reg
    â”‚   â”œâ”€â”€ train_exit_model.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.data_provider.save_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.model_io.save_model
    â”‚   â”‚     - pandas
    â”‚   â”‚     - sklearn.ensemble.RandomForestClassifier
    â”‚   â”‚     - sklearn.metrics.accuracy_score
    â”‚   â”‚     - sklearn.metrics.classification_report
    â”‚   â”‚     - sklearn.model_selection.train_test_split
    â”‚   â”‚   Function: train_exit_model
    â”‚   â”œâ”€â”€ train_meta_model.py
    â”‚   â””â”€â”€ train_stock_filter_model.py
    â”‚       Imports:
    â”‚         - core.config.settings
    â”‚         - core.data_provider.load_data
    â”‚         - core.logger.logger
    â”‚         - core.model_io.save_model
    â”‚         - optuna
    â”‚         - pandas
    â”‚         - sklearn.ensemble.RandomForestClassifier
    â”‚         - sklearn.metrics.accuracy_score
    â”‚         - sklearn.metrics.classification_report
    â”‚         - sklearn.model_selection.train_test_split
    â”‚       Function: train_stock_filter_model
    â”‚         Docstring:
    â”‚         Train a RandomForest-based stock filter model using
    â”‚         features.
    â”‚       Function: objective
    â”œâ”€â”€ paper_trader.py
    â”‚   Imports:
    â”‚     - core.logger.logger
    â”‚     - datetime.datetime
    â”‚     - os
    â”‚     - pandas
    â”‚     - yfinance
    â”‚   Function: load_recommendations
    â”‚   Function: load_open_positions
    â”‚   Function: load_today_price
    â”‚   Function: enter_trades
    â”‚   Function: check_exit_condition
    â”‚   Function: exit_trades
    â”‚   Function: log_trades
    â”‚   Function: main
    â”œâ”€â”€ predictive_trader
    â”‚   â”œâ”€â”€ A_tester.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - os
    â”‚   â”‚     - predictive_trader.price_predictor_lgbm.train_lgbm_model
    â”‚   â”‚     - predictive_trader.price_predictor_lstm.train_lstm_model
    â”‚   â”‚     - predictive_trader.trade_signal_generator.generate_signals_for_list
    â”‚   â”œâ”€â”€ __pycache__/  [directory excluded]
    â”‚   â”œâ”€â”€ backtest_lstm_predictor.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - config.paths.PATHS
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - datetime.timedelta
    â”‚   â”‚     - numpy
    â”‚   â”‚     - os
    â”‚   â”‚     - pandas
    â”‚   â”‚     - predictive_trader.price_predictor_lstm_v2.FEATURE_WINDOW
    â”‚   â”‚     - predictive_trader.price_predictor_lstm_v2.FUTURE_OFFSET
    â”‚   â”‚     - predictive_trader.price_predictor_lstm_v2.predict_5day_return_v2
    â”‚   â”‚     - predictive_trader.price_predictor_lstm_v2.train_lstm_model_v2
    â”‚   â”‚   Function: backtest_lstm_predictor
    â”‚   â”œâ”€â”€ curve_predictor.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - config.paths.PATHS
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.time_context.get_simulation_date
    â”‚   â”‚     - db.db_router.insert_dataframe
    â”‚   â”‚     - db.db_router.run_query
    â”‚   â”‚     - os
    â”‚   â”‚     - pandas
    â”‚   â”‚     - predictive_trader.price_predictor_lstm.predict_next_5days_lstm
    â”‚   â”‚     - predictive_trader.price_predictor_lstm.train_lstm_model
    â”‚   â”‚   Function: generate_curves_for_list
    â”‚   â”œâ”€â”€ curve_signal_generator.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.time_context.get_simulation_date
    â”‚   â”‚     - db.db_router.insert_dataframe
    â”‚   â”‚     - db.db_router.run_query
    â”‚   â”‚     - pandas
    â”‚   â”‚   Function: generate_signals_from_curves
    â”‚   â”œâ”€â”€ model_manager.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - config.paths.PATHS
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - datetime.datetime
    â”‚   â”‚     - joblib
    â”‚   â”‚     - numpy
    â”‚   â”‚     - os
    â”‚   â”‚     - pandas
    â”‚   â”‚     - sklearn.preprocessing.MinMaxScaler
    â”‚   â”‚     - tensorflow
    â”‚   â”‚     - tensorflow.keras.Input
    â”‚   â”‚     - tensorflow.keras.layers.Dense
    â”‚   â”‚     - tensorflow.keras.layers.LSTM
    â”‚   â”‚     - tensorflow.keras.models.Sequential
    â”‚   â”‚   Function: build_lstm_model
    â”‚   â”‚   Function: load_price_data
    â”‚   â”‚   Function: train_model_upto
    â”‚   â”‚   Function: load_model_for_date
    â”‚   â”œâ”€â”€ price_predictor_lgbm.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - config.paths.PATHS
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - joblib
    â”‚   â”‚     - lightgbm
    â”‚   â”‚     - numpy
    â”‚   â”‚     - os
    â”‚   â”‚     - pandas
    â”‚   â”‚   Function: generate_features
    â”‚   â”‚   Function: compute_rsi
    â”‚   â”‚   Function: load_price_data
    â”‚   â”‚   Function: train_lgbm_model
    â”‚   â”‚   Function: predict_movement_lgbm
    â”‚   â”œâ”€â”€ price_predictor_lstm.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - config.paths.PATHS
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.time_context.get_simulation_date
    â”‚   â”‚     - datetime.datetime
    â”‚   â”‚     - db.db_router.insert_dataframe
    â”‚   â”‚     - joblib
    â”‚   â”‚     - numpy
    â”‚   â”‚     - os
    â”‚   â”‚     - pandas
    â”‚   â”‚     - predictive_trader.model_manager.load_model_for_date
    â”‚   â”‚     - sklearn.preprocessing.MinMaxScaler
    â”‚   â”‚     - tensorflow
    â”‚   â”‚     - tensorflow.keras.Input
    â”‚   â”‚     - tensorflow.keras.layers.Dense
    â”‚   â”‚     - tensorflow.keras.layers.LSTM
    â”‚   â”‚     - tensorflow.keras.models.Sequential
    â”‚   â”‚   Function: build_lstm_model
    â”‚   â”‚   Function: load_price_data
    â”‚   â”‚   Function: train_lstm_model
    â”‚   â”‚   Function: predict_next_5days_lstm
    â”‚   â”‚   Function: save_5day_predictions
    â”‚   â”œâ”€â”€ price_predictor_lstm_intraday.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - config.paths.PATHS
    â”‚   â”‚     - core.data_provider.fetch_stock_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - datetime.time
    â”‚   â”‚     - joblib
    â”‚   â”‚     - numpy
    â”‚   â”‚     - os
    â”‚   â”‚     - pandas
    â”‚   â”‚     - sklearn.preprocessing.MinMaxScaler
    â”‚   â”‚     - tensorflow.keras.Input
    â”‚   â”‚     - tensorflow.keras.layers.Dense
    â”‚   â”‚     - tensorflow.keras.layers.LSTM
    â”‚   â”‚     - tensorflow.keras.models.Sequential
    â”‚   â”‚     - tensorflow.keras.models.load_model
    â”‚   â”‚   Function: build_model
    â”‚   â”‚   Function: train_intraday_model
    â”‚   â”‚   Function: predict_intraday_return
    â”‚   â”œâ”€â”€ price_predictor_lstm_v2.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - config.paths.PATHS
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - joblib
    â”‚   â”‚     - numpy
    â”‚   â”‚     - os
    â”‚   â”‚     - pandas
    â”‚   â”‚     - sklearn.preprocessing.MinMaxScaler
    â”‚   â”‚     - tensorflow.keras.Input
    â”‚   â”‚     - tensorflow.keras.layers.Dense
    â”‚   â”‚     - tensorflow.keras.layers.LSTM
    â”‚   â”‚     - tensorflow.keras.models.Sequential
    â”‚   â”‚     - tensorflow.keras.models.load_model
    â”‚   â”‚   Function: build_model
    â”‚   â”‚   Function: train_lstm_model_v2
    â”‚   â”‚   Function: predict_5day_return_v2
    â”‚   â””â”€â”€ trade_signal_generator.py
    â”‚       Imports:
    â”‚         - core.data_provider.fetch_stock_data
    â”‚         - core.logger.logger
    â”‚         - datetime.datetime
    â”‚         - db.db_router.insert_dataframe
    â”‚         - os
    â”‚         - pandas
    â”‚         - predictive_trader.price_predictor_lgbm.predict_movement_lgbm
    â”‚         - predictive_trader.price_predictor_lstm.predict_next_close_lstm
    â”‚         - predictive_trader.price_predictor_lstm.predict_next_n_days_lstm
    â”‚       Function: generate_trade_signal
    â”‚       Function: generate_signals_for_list
    â”œâ”€â”€ prefect.yaml
    â”œâ”€â”€ project_data
    â”‚   â”œâ”€â”€ archive
    â”‚   â”œâ”€â”€ logs
    â”‚   â”œâ”€â”€ meta
    â”‚   â”œâ”€â”€ models
    â”‚   â”œâ”€â”€ predictions
    â”‚   â”œâ”€â”€ processed
    â”‚   â”œâ”€â”€ raw
    â”‚   â”œâ”€â”€ results
    â”‚   â”‚   ğŸ“„ Skipped 4 data files (.csv, .json, .pyc)
    â”‚   â”‚   â””â”€â”€ history
    â”‚   â”œâ”€â”€ secrets
    â”‚   â””â”€â”€ trading_system.db
    â”œâ”€â”€ project_summary.txt
    â”œâ”€â”€ readme.md
    â”œâ”€â”€ report_generator.py
    â”‚   Imports:
    â”‚     - core.logger.logger
    â”‚     - datetime.datetime
    â”‚     - matplotlib.pyplot
    â”‚     - os
    â”‚     - pandas
    â”‚     - yfinance
    â”‚   Function: load_data
    â”‚   Function: analyze_trades
    â”‚   Function: fetch_current_price
    â”‚   Function: analyze_open_positions
    â”‚   Function: main
    â”œâ”€â”€ results
    â”œâ”€â”€ scripts
    â”‚   â”œâ”€â”€ __archive__
    â”‚   â”‚   â”œâ”€â”€ execution_agent.py
    â”‚   â”‚   â”‚   Imports:
    â”‚   â”‚   â”‚     - config.paths.PATHS
    â”‚   â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚   â”‚     - core.data_provider.save_data
    â”‚   â”‚   â”‚     - core.logger.logger
    â”‚   â”‚   â”‚     - datetime.datetime
    â”‚   â”‚   â”‚     - os
    â”‚   â”‚   â”‚     - pandas
    â”‚   â”‚   â”‚     - time
    â”‚   â”‚   â”‚     - utils.file_io.load_dataframe
    â”‚   â”‚   â”‚     - utils.file_io.save_dataframe
    â”‚   â”‚   â”‚     - yfinance
    â”‚   â”‚   â”‚   Class: ExecutionAgent
    â”‚   â”‚   â”‚     Methods:
    â”‚   â”‚   â”‚       - __init__
    â”‚   â”‚   â”‚       - load_recommendations
    â”‚   â”‚   â”‚       - load_open_positions
    â”‚   â”‚   â”‚       - load_today_price
    â”‚   â”‚   â”‚       - check_exit_condition
    â”‚   â”‚   â”‚       - log_trades
    â”‚   â”‚   â”‚       - enter_trades
    â”‚   â”‚   â”‚       - exit_trades
    â”‚   â”‚   â”‚       - run
    â”‚   â”‚   â”œâ”€â”€ historical_data
    â”‚   â”‚   â”‚   ğŸ“„ Skipped 666 data files (.csv, .json, .pyc)
    â”‚   â”‚   â”œâ”€â”€ planner_agent.py
    â”‚   â”‚   â”‚   Imports:
    â”‚   â”‚   â”‚     - agents.execution_agent_sql.ExecutionAgent
    â”‚   â”‚   â”‚     - agents.memory_agent.MemoryAgent
    â”‚   â”‚   â”‚     - agents.strategy_agent.StrategyAgent
    â”‚   â”‚   â”‚     - config.paths.PATHS
    â”‚   â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚   â”‚     - core.data_provider.save_data
    â”‚   â”‚   â”‚     - core.logger.logger
    â”‚   â”‚   â”‚     - datetime.datetime
    â”‚   â”‚   â”‚     - fundamentals.fundamental_data_extractor
    â”‚   â”‚   â”‚     - models.stock_filter_predictor.run_stock_filter
    â”‚   â”‚   â”‚     - os
    â”‚   â”‚   â”‚     - pandas
    â”‚   â”‚   â”‚     - services.feedback_loop.update_training_data
    â”‚   â”‚   â”‚     - stock_selecter.auto_filter_selector.auto_select_filter
    â”‚   â”‚   â”‚     - utils.file_io.save_dataframe
    â”‚   â”‚   â”‚   Class: PlannerAgent
    â”‚   â”‚   â”‚     Methods:
    â”‚   â”‚   â”‚       - __init__
    â”‚   â”‚   â”‚       - run_weekly_routine
    â”‚   â”‚   â””â”€â”€ train_dual_model.py
    â”‚   â”‚       Imports:
    â”‚   â”‚         - config.paths.PATHS
    â”‚   â”‚         - core.logger.logger
    â”‚   â”‚         - core.model_io.load_model
    â”‚   â”‚         - core.model_io.save_model
    â”‚   â”‚         - json
    â”‚   â”‚         - os
    â”‚   â”‚         - pandas
    â”‚   â”‚         - pickle
    â”‚   â”‚         - sklearn.ensemble.RandomForestClassifier
    â”‚   â”‚         - sklearn.ensemble.RandomForestRegressor
    â”‚   â”‚         - sklearn.metrics.classification_report
    â”‚   â”‚         - sklearn.metrics.mean_squared_error
    â”‚   â”‚         - sklearn.model_selection.train_test_split
    â”‚   â”‚         - sklearn.preprocessing.LabelEncoder
    â”‚   â”‚         - utils.file_io.load_dataframe
    â”‚   â”‚       Function: train_dual_models
    â”‚   â”œâ”€â”€ __pycache__/  [directory excluded]
    â”‚   â”œâ”€â”€ check_db_orm_match.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - db.models.Base
    â”‚   â”‚     - sqlalchemy.create_engine
    â”‚   â”‚     - sqlalchemy.inspect
    â”‚   â”‚   Function: check_schema
    â”‚   â”œâ”€â”€ fetch_instruments.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - integrations.zerodha_client.get_kite
    â”‚   â”‚     - pandas
    â”‚   â”œâ”€â”€ generate_token.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - json
    â”‚   â”‚     - kiteconnect.KiteConnect
    â”‚   â”‚     - os
    â”‚   â”‚     - webbrowser
    â”‚   â”œâ”€â”€ load_backup_fundamentals.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.data_provider.save_data
    â”‚   â”‚     - pandas
    â”‚   â”œâ”€â”€ reset_system.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - argparse
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - db.db_router.run_query
    â”‚   â”‚     - os
    â”‚   â”‚     - pathlib.Path
    â”‚   â”‚     - shutil
    â”‚   â”‚     - sys
    â”‚   â”‚   Function: drop_partitioned_feature_tables
    â”‚   â”‚   Function: delete_model_files
    â”‚   â”‚   Function: clear_cache_dirs
    â”‚   â”‚   Function: main
    â”‚   â””â”€â”€ seed_training_data.py
    â”‚       Imports:
    â”‚         - core.data_provider.load_data
    â”‚         - core.data_provider.save_data
    â”‚         - core.logger.logger
    â”‚         - pandas
    â”‚       Function: seed_training_data
    â”œâ”€â”€ services
    â”‚   â”œâ”€â”€ __pycache__/  [directory excluded]
    â”‚   â””â”€â”€ feedback_loop.py
    â”‚       Imports:
    â”‚         - core.config.settings
    â”‚         - core.data_provider.load_data
    â”‚         - core.data_provider.save_data
    â”‚         - core.logger.logger
    â”‚         - core.time_context.get_simulation_date
    â”‚         - pandas
    â”‚       Function: update_training_data
    â”œâ”€â”€ stock_selecter
    â”‚   ğŸ“„ Skipped 2 data files (.csv, .json, .pyc)
    â”‚   â”œâ”€â”€ __pycache__/  [directory excluded]
    â”‚   â”œâ”€â”€ auto_filter_selector.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - datetime.datetime
    â”‚   â”‚     - os
    â”‚   â”‚     - pandas
    â”‚   â”‚     - stock_selecter.fallback_technical_filter.run_technical_filter
    â”‚   â”‚     - stock_selecter.stock_screener.run_stock_filter
    â”‚   â”‚   Function: auto_select_filter
    â”‚   â”œâ”€â”€ fallback_technical_filter.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.config.settings
    â”‚   â”‚     - core.data_provider.load_data
    â”‚   â”‚     - core.data_provider.save_data
    â”‚   â”‚     - core.logger.logger
    â”‚   â”‚     - core.time_context.get_simulation_date
    â”‚   â”‚     - datetime.datetime
    â”‚   â”‚     - pandas
    â”‚   â”‚   Function: run_technical_filter
    â”‚   â””â”€â”€ stock_screener.py
    â”‚       Imports:
    â”‚         - core.config.settings
    â”‚         - core.data_provider.load_data
    â”‚         - core.data_provider.save_data
    â”‚         - core.logger.logger
    â”‚         - datetime.datetime
    â”‚         - pandas
    â”‚       Function: filter_growth_stocks
    â”‚       Function: filter_value_stocks
    â”‚       Function: filter_momentum_stocks
    â”‚       Function: filter_defensive_stocks
    â”‚       Function: filter_small_cap_gems
    â”‚       Function: filter_high_volatility_stocks
    â”‚       Function: run_stock_filter
    â”‚         Docstring:
    â”‚         1) Load fundamentals 2) Apply filter_name 3) Persist only
    â”‚         'stock' (+ timestamp) back to SQL
    â”‚       Function: get_stock_list
    â”‚         Docstring:
    â”‚         Read back the ML-selected table for downstream use.
    â”œâ”€â”€ tests
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ __pycache__/  [directory excluded]
    â”‚   â”œâ”€â”€ conftest.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - pandas
    â”‚   â”‚     - pytest
    â”‚   â”‚   Function: dummy_training_data
    â”‚   â”‚     Docstring:
    â”‚   â”‚     Very small fixture DataFrame for unit tests.
    â”‚   â”œâ”€â”€ test_data_audit.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - analysis.data_audit.main
    â”‚   â”‚     - core.data_provider
    â”‚   â”‚     - json
    â”‚   â”‚     - pandas
    â”‚   â”‚     - pathlib.Path
    â”‚   â”‚     - sys
    â”‚   â”‚   Function: test_data_audit_threshold_behavior
    â”‚   â”‚   Function: mock_load_data
    â”‚   â”œâ”€â”€ test_data_checks.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - core.validation.data_checks.check_missing
    â”‚   â”‚     - core.validation.data_checks.class_balance
    â”‚   â”‚     - core.validation.data_checks.detect_outliers
    â”‚   â”‚     - numpy
    â”‚   â”‚     - pandas
    â”‚   â”‚   Function: test_check_missing
    â”‚   â”‚   Function: test_class_balance
    â”‚   â”‚   Function: test_detect_outliers_zscore
    â”‚   â”‚   Function: test_detect_outliers_iqr
    â”‚   â”‚   Function: test_detect_outliers_zscore
    â”‚   â”œâ”€â”€ test_feature_pipeline.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - analysis.feature_pipeline.check_temporal_alignment
    â”‚   â”‚     - analysis.feature_pipeline.detect_high_correlation
    â”‚   â”‚     - numpy
    â”‚   â”‚     - pandas
    â”‚   â”‚     - pytest
    â”‚   â”‚   Function: test_temporal_alignment_pass
    â”‚   â”‚   Function: test_temporal_alignment_fail
    â”‚   â”‚   Function: test_high_correlation_detection
    â”‚   â”œâ”€â”€ test_feedback_loop.py
    â”‚   â”‚   Imports:
    â”‚   â”‚     - analysis.feedback_loop.main
    â”‚   â”‚     - core.data_provider
    â”‚   â”‚     - pandas
    â”‚   â”‚     - pytest
    â”‚   â”‚   Function: dummy_feedback_data
    â”‚   â”‚   Function: test_feedback_loop_kpis
    â”‚   â””â”€â”€ test_model_health.py
    â”‚       Imports:
    â”‚         - analysis.model_health
    â”‚         - core.data_provider
    â”‚         - os
    â”‚         - pandas
    â”‚         - pytest
    â”‚       Function: dummy_model_metadata
    â”‚       Function: test_model_drift_detection
    â”œâ”€â”€ train_strategy_selector.py
    â”‚   Imports:
    â”‚     - core.logger.logger
    â”‚     - pandas
    â”‚     - pickle
    â”‚     - sklearn.ensemble.RandomForestRegressor
    â”‚     - sklearn.model_selection.train_test_split
    â”‚     - sklearn.multioutput.MultiOutputRegressor
    â”‚   Function: train_strategy_selector
    â””â”€â”€ utils
        â”œâ”€â”€ __pycache__/  [directory excluded]
        â”œâ”€â”€ file_io.py
        â”‚   Imports:
        â”‚     - core.logger.logger
        â”‚     - os
        â”‚     - pandas
        â”‚   Function: load_dataframe
        â”‚   Function: save_dataframe
        â”œâ”€â”€ precheck_features.py
        â”‚   Imports:
        â”‚     - config.paths.PATHS
        â”‚     - core.data_provider.load_data
        â”‚     - core.feature_generator.generate_features
        â”‚     - core.logger.logger
        â”‚     - core.model_io.load_model
        â”‚     - datetime.datetime
        â”‚     - json
        â”‚     - os
        â”‚     - pandas
        â”‚   Function: get_model_features
        â”‚   Function: is_feature_usable
        â”‚   Function: prefilter_valid_stocks
        â”œâ”€â”€ progress_logger.py
        â”‚   Imports:
        â”‚     - datetime.datetime
        â”‚     - sqlite3
        â”‚   Function: log_model_progress
        â”œâ”€â”€ skiplist_manager.py
        â”‚   Imports:
        â”‚     - db.db_router.run_query
        â”‚     - json
        â”‚     - os
        â”‚   Function: load_skiplist
        â”‚   Function: add_to_skiplist
        â”‚   Function: load_failed_precheck
        â”‚   Function: add_failed_precheck
        â”œâ”€â”€ sql_utils.py
        â”‚   Imports:
        â”‚     - config.sql_tables.SQL_TABLES
        â”‚   Function: is_sql_table
        â”œâ”€â”€ stock_health_precheck.py
        â”‚   Imports:
        â”‚     - core.data_provider.load_data
        â”‚     - core.logger.logger
        â”‚   Function: is_stock_tradeable
        â”œâ”€â”€ stock_precheck.py
        â”‚   Imports:
        â”‚     - config.paths.PATHS
        â”‚     - core.feature_generator.generate_features
        â”‚     - core.logger.logger
        â”‚     - core.model_io.load_model
        â”‚   Function: is_feature_ready
        â”‚   Function: filter_valid_stocks
        â””â”€â”€ technical_indicators.py
            Imports:
              - pandas
            Function: compute_sma
            Function: compute_rsi
