Project Structure & Python File Details for: Y:\Trading\stock_selection

🧠 Detected Data Access Points:
• .venv/Lib/site-packages/statsmodels/genmod/tests/test_gee.py → load_data('gee_linear_1.csv', source_dest='default')
• .venv/Lib/site-packages/statsmodels/genmod/tests/test_gee.py → load_data('gee_linear_1.csv', source_dest='default')
• .venv/Lib/site-packages/statsmodels/genmod/tests/test_gee.py → load_data('gee_logistic_1.csv', source_dest='default')
• .venv/Lib/site-packages/statsmodels/genmod/tests/test_gee.py → load_data('gee_logistic_1.csv', source_dest='default')
• .venv/Lib/site-packages/statsmodels/genmod/tests/test_gee.py → load_data('gee_nested_linear_1.csv', source_dest='default')
• .venv/Lib/site-packages/statsmodels/genmod/tests/test_gee.py → load_data('gee_nominal_1.csv', source_dest='default')
• .venv/Lib/site-packages/statsmodels/genmod/tests/test_gee.py → load_data('gee_nominal_1.csv', source_dest='default')
• .venv/Lib/site-packages/statsmodels/genmod/tests/test_gee.py → load_data('gee_nominal_1.csv', source_dest='default')
• .venv/Lib/site-packages/statsmodels/genmod/tests/test_gee.py → load_data('gee_ordinal_1.csv', source_dest='default')
• .venv/Lib/site-packages/statsmodels/genmod/tests/test_gee.py → load_data('gee_ordinal_1.csv', source_dest='default')
• .venv/Lib/site-packages/statsmodels/genmod/tests/test_gee.py → load_data('gee_ordinal_1.csv', source_dest='default')
• .venv/Lib/site-packages/statsmodels/genmod/tests/test_gee.py → load_data('gee_ordinal_1.csv', source_dest='default')
• .venv/Lib/site-packages/statsmodels/genmod/tests/test_gee.py → load_data('gee_poisson_1.csv', source_dest='default')
• .venv/Lib/site-packages/statsmodels/genmod/tests/test_gee.py → load_data('gee_poisson_1.csv', source_dest='default')
• .venv/Lib/site-packages/statsmodels/genmod/tests/test_gee.py → load_data('gee_poisson_1.csv', source_dest='default')
• .venv/Lib/site-packages/statsmodels/genmod/tests/test_gee.py → load_data('gee_poisson_1.csv', source_dest='default')
• .venv/Lib/site-packages/statsmodels/tsa/vector_ar/tests/test_var_jmulti.py → load_data('None', source_dest='default')
• .venv/Lib/site-packages/statsmodels/tsa/vector_ar/tests/test_vecm.py → load_data('None', source_dest='default')
• agents/execution/execution_agent_sql.py → load_data('None', source_dest='default')
• agents/joint_policy_runner.py → load_data('None', source_dest='default')
• agents/memory/feedback_loop.py → load_data('None', source_dest='default')
• agents/memory/feedback_loop.py → save_data('None', source_dest='default')
• agents/memory/memory_agent.py → load_data('None', source_dest='default')
• agents/memory/memory_agent.py → load_data('None', source_dest='default')
• agents/memory/memory_agent.py → load_data('None', source_dest='default')
• agents/missed_trade_logger.py → load_data('None', source_dest='default')
• agents/missed_trade_logger.py → load_data('None', source_dest='default')
• agents/planner/intraday_planner_agent.py → load_data('None', source_dest='default')
• agents/planner/intraday_planner_agent.py → load_data('None', source_dest='default')
• agents/planner/planner_agent_sql.py → load_data('None', source_dest='default')
• agents/planner/planner_agent_sql.py → load_data('None', source_dest='default')
• agents/planner/planner_agent_sql.py → load_data('None', source_dest='default')
• agents/planner/planner_agent_sql.py → load_data('None', source_dest='default')
• agents/planner/planner_agent_sql.py → load_data('None', source_dest='default')
• agents/planner/planner_agent_sql.py → load_data('None', source_dest='default')
• agents/portfolio_allocator.py → load_data('None', source_dest='default')
• agents/strategy/predictive_trader/backtest_lstm_predictor.py → load_data('stock_features', source_dest='default')
• agents/strategy/predictive_trader/curve_signal_generator.py → load_data('None', source_dest='default')
• agents/strategy/predictive_trader/model_manager.py → load_data('stock_price_history', source_dest='default')
• agents/strategy/predictive_trader/price_predictor_lgbm.py → load_data('stock_price_history', source_dest='default')
• agents/strategy/predictive_trader/price_predictor_lstm.py → load_data('stock_price_history', source_dest='default')
• agents/strategy/predictive_trader/price_predictor_lstm_v2.py → load_data('stock_features', source_dest='default')
• agents/strategy/predictive_trader/price_predictor_lstm_v2.py → load_data('stock_features', source_dest='default')
• agents/strategy/strategy_agent_old.py → load_data('None', source_dest='default')
• agents/strategy/strategy_agent_old.py → load_data('stock_price_history', source_dest='default')
• agents/time_series_agent.py → load_data('None', source_dest='default')
• analysis/joint_policy_comparator.py → load_data('joint_policy_predictions', source_dest='default')
• analysis/joint_policy_comparator.py → load_data('trades', source_dest='default')
• core/data_provider/data_provider.py → save_data('None', source_dest='default')
• core/data_provider/data_provider.py → save_data('None', source_dest='default')
• core/data_provider/data_provider.py → save_data('None', source_dest='default')
• core/data_provider/fundamentals/fundamental_data_extractor.py → load_data('None', source_dest='default')
• core/data_provider/fundamentals/fundamental_data_extractor.py → save_data('None', source_dest='default')
• core/data_provider/processing/data_pipeline/zerodha_to_postgres.py → load_data('None', source_dest='default')
• core/data_provider/processing/data_pipeline/zerodha_to_postgres.py → save_data('None', source_dest='default')
• core/feature_engineering/feature_provider_old.py → load_data('None', source_dest='default')
• core/model_io.py → load_data('None', source_dest='default')
• core/system_state.py → load_data('None', source_dest='default')
• core/system_state.py → load_data('None', source_dest='default')
• core/system_state.py → load_data('None', source_dest='default')
• core/system_state.py → load_data('None', source_dest='default')
• core/system_state.py → load_data('None', source_dest='default')
• diagnosis/evaluate_model_curves.py → load_data('None', source_dest='default')
• diagnosis/evaluate_model_curves.py → load_data('None', source_dest='default')
• diagnosis/view_predicted_curves.py → load_data('None', source_dest='default')
• diagnosis/view_predicted_curves.py → load_data('None', source_dest='default')
• flows/auto_pipeline.py → load_data('None', source_dest='default')
• flows/auto_pipeline.py → load_data('None', source_dest='default')
• flows/auto_pipeline.py → save_data('None', source_dest='default')
• flows/backfill_1m_features_flow.py → save_data('None', source_dest='default')
• flows/fundamental_pipeline.py → load_data('None', source_dest='default')
• flows/fundamental_pipeline.py → load_data('None', source_dest='default')
• flows/fundamental_pipeline.py → save_data('None', source_dest='default')
• flows/trading_pipeline.py → load_data('None', source_dest='default')
• flows/trading_pipeline.py → load_data('None', source_dest='default')
• models/meta_strategy_selector.py → save_data('None', source_dest='default')
• models/ml_dual_model_prediction_sql.py → load_data('None', source_dest='default')
• models/ml_dual_model_prediction_sql.py → load_data('None', source_dest='default')
• models/ml_training_sql.py → load_data('None', source_dest='default')
• models/ml_training_sql.py → save_data('None', source_dest='default')
• models/stock_filter_predictor.py → load_data('None', source_dest='default')
• models/stock_filter_predictor.py → save_data('None', source_dest='default')
• models/train_dual_model_sql.py → load_data('None', source_dest='default')
• models/train_entry_exit_model.py → load_data('paper_trades', source_dest='default')
• models/train_exit_model.py → load_data('None', source_dest='default')
• models/train_meta_model.py → load_data('None', source_dest='default')
• models/train_meta_model.py → save_data('None', source_dest='default')
• models/train_param_model.py → load_data('None', source_dest='default')
• models/train_stock_filter_model.py → load_data('training_data', source_dest='default')
• report_generator.py → load_data('None', source_dest='default')
• reports/daily_snapshot.py → load_data('None', source_dest='default')
• scripts/__archive__/execution_agent.py → load_data('open_positions', source_dest='default')
• scripts/__archive__/execution_agent.py → load_data('recommendations', source_dest='default')
• scripts/__archive__/execution_agent.py → save_data('None', source_dest='default')
• scripts/__archive__/planner_agent.py → load_data('ml_selected_stocks', source_dest='default')
• scripts/__archive__/planner_agent.py → save_data('None', source_dest='default')
• scripts/load_backup_fundamentals.py → save_data('None', source_dest='default')
• scripts/seed_training_data.py → load_data('paper_trades', source_dest='default')
• scripts/seed_training_data.py → load_data('stock_features', source_dest='default')
• scripts/seed_training_data.py → save_data('None', source_dest='default')
• stock_selecter/auto_filter_selector.py → load_data('None', source_dest='default')
• stock_selecter/fallback_technical_filter.py → load_data('None', source_dest='default')
• stock_selecter/fallback_technical_filter.py → save_data('None', source_dest='default')
• stock_selecter/stock_screener.py → load_data('None', source_dest='default')
• stock_selecter/stock_screener.py → load_data('None', source_dest='default')
• stock_selecter/stock_screener.py → save_data('None', source_dest='default')
• training/train_joint_policy.py → load_data('None', source_dest='default')
• training/train_joint_policy.py → load_data('None', source_dest='default')
• utils/precheck_features.py → load_data('None', source_dest='default')
• utils/precheck_features.py → load_data('None', source_dest='default')
• utils/stock_health_precheck.py → load_data('None', source_dest='default')

📁 Full Directory Summary with Code Info:
└── stock_selection
    📄 Skipped 6 data files (.csv, .json, .pyc)
    ├── Dockerfile
    ├── RL_bootstrap_notes.md
    ├── aaa.py
    │   Imports:
    │     - core.data_provider.data_provider.fetch_stock_data
    ├── aab.py
    │   Imports:
    │     - argparse
    │     - ast
    │     - collections.Counter
    │     - collections.defaultdict
    │     - hashlib
    │     - json
    │     - os
    │     - re
    │     - time
    │   Function: load_config
    │   Function: attach_parents
    │   Function: compute_cyclomatic_complexity
    │   Function: get_docstring_info
    │   Function: hash_file_contents
    │   Function: get_qualified_call_name
    │   Function: extract_general_data_flow
    │   Function: extract_configured_io_calls
    │   Function: extract_db_tables_and_features
    │   Function: parse_python_file
    │   Function: scan_project
    │   Function: main
    ├── aac
    ├── agents
    │   ├── allocator_agent.py
    │   │   Imports:
    │   │     - core.logger.logger.logger
    │   │     - core.system_state.get_system_config
    │   │     - core.system_state.update_system_config
    │   │     - db.postgres_manager.run_query
    │   │   Class: AllocatorAgent
    │   │     Methods:
    │   │       - __init__
    │   │       - get_sharpe
    │   │       - get_current_allocation
    │   │       - set_current_allocation
    │   │       - run
    │   ├── arbitration
    │   │   └── signal_arbitration_agent.py
    │   │       Imports:
    │   │         - agents.replay_logger.log_replay_row
    │   │         - core.logger.logger.logger
    │   │         - predict.ppo_live_policy.PPOLivePolicy
    │   │       Class: SignalArbitrationAgent
    │   │         Methods:
    │   │           - __init__
    │   │           - arbitrate
    │   ├── execution
    │   │   └── execution_agent_sql.py
    │   │       Imports:
    │   │         - core.config.config.settings
    │   │         - core.data_provider.data_provider.fetch_stock_data
    │   │         - core.data_provider.data_provider.load_data
    │   │         - core.event_bus.publish_event
    │   │         - core.feature_engineering.feature_enricher_multi.enrich_multi_interval_features
    │   │         - core.logger.logger.logger
    │   │         - core.logger.system_logger.log_event
    │   │         - core.time_context.time_context.get_simulation_date
    │   │         - datetime.datetime
    │   │         - db.conflict_utils.insert_with_conflict_handling
    │   │         - db.postgres_manager.run_query
    │   │         - db.replay_buffer_sql.insert_replay_episode
    │   │         - json
    │   │         - os
    │   │         - pandas
    │   │         - rl.replay_buffer.ReplayBuffer
    │   │         - services.exit_policy_evaluator.get_exit_probability
    │   │         - time
    │   │       Class: ExecutionAgentSQL
    │   │         Methods:
    │   │           - __init__
    │   │           - load_signals
    │   │           - load_open_positions
    │   │           - load_today_ohlc
    │   │           - exit_trades
    │   │           - enter_trades
    │   │           - publish_m2m_update
    │   │           - run
    │   │       Function: safe_load_table
    │   ├── feedback_collector.py
    │   │   Imports:
    │   │     - core.event_bus.subscribe_to_events
    │   │     - core.logger.logger.logger
    │   │     - db.replay_buffer_sql.insert_replay_episode
    │   │   Function: handle_trade_close
    │   ├── joint_policy_runner.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.feature_provider.fetch_features
    │   │     - core.logger.logger.logger
    │   │     - core.time_context.time_context.get_simulation_date
    │   │     - datetime.datetime
    │   │     - db.conflict_utils.insert_with_conflict_handling
    │   │     - models.joint_policy.JointPolicyModel
    │   │     - pandas
    │   │   Function: run_joint_policy_predictions
    │   ├── memory
    │   │   ├── feedback_loop.py
    │   │   │   Imports:
    │   │   │     - core.config.config.settings
    │   │   │     - core.data_provider.data_provider.load_data
    │   │   │     - core.data_provider.data_provider.save_data
    │   │   │     - core.feature_engineering.feature_enricher_multi.enrich_multi_interval_features
    │   │   │     - core.logger.logger.logger
    │   │   │     - core.time_context.time_context.get_simulation_date
    │   │   │     - json
    │   │   │     - pandas
    │   │   │     - pytz.timezone
    │   │   │     - rl.replay_buffer.ReplayBuffer
    │   │   │   Function: parse_exit_field
    │   │   │   Function: update_training_data
    │   │   │   Function: compute_missed_profit
    │   │   │   Function: compute_holding_penalty
    │   │   └── memory_agent.py
    │   │       Imports:
    │   │         - agents.memory.feedback_loop.update_training_data
    │   │         - core.config.config.settings
    │   │         - core.data_provider.data_provider.load_data
    │   │         - core.logger.logger.logger
    │   │         - core.logger.system_logger.log_event
    │   │         - core.model_io.save_model
    │   │         - core.time_context.time_context.get_simulation_date
    │   │         - db.conflict_utils.insert_with_conflict_handling
    │   │         - db.postgres_manager.run_query
    │   │         - db.replay_buffer_sql.count_by_stock
    │   │         - models.meta_strategy_selector.train_meta_model
    │   │         - models.train_dual_model_sql.train_dual_model
    │   │         - models.train_exit_model.train_exit_model
    │   │         - models.train_stock_filter_model.train_stock_filter_model
    │   │         - pandas
    │   │         - rl.rl_finetune.finetune_rl
    │   │       Class: MemoryAgent
    │   │         Methods:
    │   │           - __init__
    │   │           - archive_table
    │   │           - summarize_weekly_performance
    │   │           - check_retraining_needed
    │   │           - feedback_loop
    │   │           - update
    │   │       Function: top_stocks_with_replay_data
    │   ├── missed_trade_logger.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.fetch_stock_data
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.event_bus.publish_event
    │   │     - core.logger.logger.logger
    │   │     - core.time_context.time_context.get_simulation_date
    │   │     - db.db.SessionLocal
    │   │     - pandas
    │   │   Function: simple_backtest_profit
    │   │     Docstring:
    │   │       A naive counterfactual: Buy at open, sell at close of the same day.
    │   │   Function: get_all_candidates
    │   │   Function: get_traded_today
    │   │   Function: run_missed_trade_logger
    │   ├── planner
    │   │   ├── intraday_planner_agent.py
    │   │   │   Imports:
    │   │   │     - agents.arbitration.signal_arbitration_agent.SignalArbitrationAgent
    │   │   │     - agents.execution.execution_agent_sql.ExecutionAgentSQL
    │   │   │     - agents.risk_management_agent.RiskManagementAgent
    │   │   │     - agents.strategy.rl_strategy_agent.RLStrategyAgent
    │   │   │     - agents.strategy.strategy_agent.StrategyAgent
    │   │   │     - core.config.config.settings
    │   │   │     - core.data_provider.data_provider.load_data
    │   │   │     - core.logger.logger.logger
    │   │   │     - core.model_io.insert_with_conflict_handling
    │   │   │     - core.time_context.time_context.get_simulation_date
    │   │   │     - os
    │   │   │     - pandas
    │   │   │     - random
    │   │   │     - redis
    │   │   │     - time
    │   │   │     - tqdm.tqdm
    │   │   │   Class: IntradayPlannerAgent
    │   │   │     Methods:
    │   │   │       - __init__
    │   │   │       - _fetch_updated_symbols
    │   │   │       - _fallback_poll
    │   │   │       - _process_symbols
    │   │   │       - run
    │   │   │       - run_forever
    │   │   ├── planner_agent_sql.py
    │   │   │   Imports:
    │   │   │     - agents.arbitration.signal_arbitration_agent.SignalArbitrationAgent
    │   │   │     - agents.execution.execution_agent_sql.ExecutionAgentSQL
    │   │   │     - agents.memory.memory_agent.MemoryAgent
    │   │   │     - agents.risk_management_agent.RiskManagementAgent
    │   │   │     - agents.strategy.rl_strategy_agent.RLStrategyAgent
    │   │   │     - agents.strategy.strategy_agent.StrategyAgent
    │   │   │     - core.config.config.settings
    │   │   │     - core.data_provider.data_provider.fetch_stock_data
    │   │   │     - core.data_provider.data_provider.load_data
    │   │   │     - core.data_provider.data_provider.save_data
    │   │   │     - core.data_provider.fundamentals.fundamental_data_extractor
    │   │   │     - core.feature_engineering.feature_enricher_multi.enrich_multi_interval_features
    │   │   │     - core.logger.logger.logger
    │   │   │     - core.logger.system_logger.log_event
    │   │   │     - core.predict.predict_param_model.predict_param_config
    │   │   │     - core.predict.predictor.predict_dual_model
    │   │   │     - core.skiplist.skiplist.add_to_skiplist
    │   │   │     - core.skiplist.skiplist.is_in_skiplist
    │   │   │     - core.system_state.get_system_config
    │   │   │     - core.time_context.time_context.get_simulation_date
    │   │   │     - datetime.datetime
    │   │   │     - db.conflict_utils.insert_with_conflict_handling
    │   │   │     - db.db.SessionLocal
    │   │   │     - db.models.Base
    │   │   │     - db.postgres_manager.get_all_symbols
    │   │   │     - db.postgres_manager.run_query
    │   │   │     - models.joint_policy.JointPolicyModel
    │   │   │     - pandas
    │   │   │     - pytz
    │   │   │     - random
    │   │   │     - sqlalchemy.text
    │   │   │     - stock_selecter.auto_filter_selector.auto_select_filter
    │   │   │     - tqdm.tqdm
    │   │   │     - warnings
    │   │   │   Class: PlannerAgentSQL
    │   │   │     Methods:
    │   │   │       - __init__
    │   │   │       - run
    │   │   │       - _fetch_fundamentals
    │   │   │       - _fetch_price_history
    │   │   │       - _refresh_features
    │   │   │       - _filter_stocks
    │   │   │       - _evaluate_stocks
    │   │   │       - _execute_trades
    │   │   │       - _update_systems
    │   │   └── planner_router.py
    │   │       Imports:
    │   │         - agents.planner.intraday_planner_agent.IntradayPlannerAgent
    │   │         - agents.planner.planner_agent_sql.PlannerAgentSQL
    │   │         - core.logger.logger.logger
    │   │         - threading
    │   │         - time
    │   │       Function: run_daily_planner
    │   │       Function: run_intraday_loop
    │   │       Function: run_all_planners
    │   ├── portfolio
    │   ├── portfolio_allocator.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.logger.logger.logger
    │   │     - datetime.datetime
    │   │     - pandas
    │   │   Class: PortfolioAllocatorAgent
    │   │     Methods:
    │   │       - __init__
    │   │       - load_open_positions
    │   │       - filter_signals
    │   ├── replay_logger.py
    │   │   Imports:
    │   │     - core.event_bus.subscribe_to_events
    │   │     - core.logger.logger.logger
    │   │     - db.db.SessionLocal
    │   │     - db.postgres_manager.run_query
    │   │     - db.replay_buffer_sql.insert_replay_episode
    │   │     - pandas
    │   │   Function: handle_event
    │   │   Function: log_replay_row
    │   │     Docstring:
    │   │       For logging rejected or skipped signals, e.g., during arbitration.
    │   ├── risk
    │   ├── risk_management_agent.py
    │   │   Imports:
    │   │     - core.logger.logger.logger
    │   │     - core.replay.replay_logger.log_replay_row
    │   │   Class: RiskManagementAgent
    │   │     Methods:
    │   │       - __init__
    │   │       - approve
    │   │         Docstring:
    │   │         Evaluate the signal against risk rules. Returns True if trade is
    │   │         allowed; False otherwise.
    │   │       - _log_reject
    │   ├── strategy
    │   │   ├── predictive_trader
    │   │   │   ├── A_tester.py
    │   │   │   │   Imports:
    │   │   │   │     - os
    │   │   │   │     - predictive_trader.price_predictor_lgbm.train_lgbm_model
    │   │   │   │     - predictive_trader.price_predictor_lstm.train_lstm_model
    │   │   │   │     - predictive_trader.trade_signal_generator.generate_signals_for_list
    │   │   │   ├── backtest_lstm_predictor.py
    │   │   │   │   Imports:
    │   │   │   │     - config.paths.PATHS
    │   │   │   │     - core.data_provider.data_provider.load_data
    │   │   │   │     - core.logger.logger.logger
    │   │   │   │     - datetime.timedelta
    │   │   │   │     - numpy
    │   │   │   │     - os
    │   │   │   │     - pandas
    │   │   │   │     - predictive_trader.price_predictor_lstm_v2.FEATURE_WINDOW
    │   │   │   │     - predictive_trader.price_predictor_lstm_v2.FUTURE_OFFSET
    │   │   │   │     - predictive_trader.price_predictor_lstm_v2.predict_5day_return_v2
    │   │   │   │     - predictive_trader.price_predictor_lstm_v2.train_lstm_model_v2
    │   │   │   │   Function: backtest_lstm_predictor
    │   │   │   ├── curve_predictor.py
    │   │   │   │   Imports:
    │   │   │   │     - config.paths.PATHS
    │   │   │   │     - core.data_provider.data_provider.load_data
    │   │   │   │     - core.logger.logger.logger
    │   │   │   │     - core.time_context.time_context.get_simulation_date
    │   │   │   │     - db.postgres_manager.insert_dataframe
    │   │   │   │     - db.postgres_manager.run_query
    │   │   │   │     - os
    │   │   │   │     - pandas
    │   │   │   │     - predictive_trader.price_predictor_lstm.predict_next_5days_lstm
    │   │   │   │     - predictive_trader.price_predictor_lstm.train_lstm_model
    │   │   │   │   Function: generate_curves_for_list
    │   │   │   ├── curve_signal_generator.py
    │   │   │   │   Imports:
    │   │   │   │     - core.data_provider.data_provider.load_data
    │   │   │   │     - core.logger.logger.logger
    │   │   │   │     - core.time_context.time_context.get_simulation_date
    │   │   │   │     - db.db_router.insert_dataframe
    │   │   │   │     - db.db_router.run_query
    │   │   │   │     - pandas
    │   │   │   │   Function: generate_signals_from_curves
    │   │   │   ├── model_manager.py
    │   │   │   │   Imports:
    │   │   │   │     - config.paths.PATHS
    │   │   │   │     - core.data_provider.data_provider.load_data
    │   │   │   │     - core.logger.logger.logger
    │   │   │   │     - datetime.datetime
    │   │   │   │     - joblib
    │   │   │   │     - numpy
    │   │   │   │     - os
    │   │   │   │     - pandas
    │   │   │   │     - sklearn.preprocessing.MinMaxScaler
    │   │   │   │     - tensorflow
    │   │   │   │     - tensorflow.keras.Input
    │   │   │   │     - tensorflow.keras.layers.Dense
    │   │   │   │     - tensorflow.keras.layers.LSTM
    │   │   │   │     - tensorflow.keras.models.Sequential
    │   │   │   │   Function: build_lstm_model
    │   │   │   │   Function: load_price_data
    │   │   │   │   Function: train_model_upto
    │   │   │   │   Function: load_model_for_date
    │   │   │   ├── price_predictor_lgbm.py
    │   │   │   │   Imports:
    │   │   │   │     - config.paths.PATHS
    │   │   │   │     - core.data_provider.data_provider.load_data
    │   │   │   │     - core.logger.logger.logger
    │   │   │   │     - joblib
    │   │   │   │     - lightgbm
    │   │   │   │     - numpy
    │   │   │   │     - os
    │   │   │   │     - pandas
    │   │   │   │   Function: generate_features
    │   │   │   │   Function: compute_rsi
    │   │   │   │   Function: load_price_data
    │   │   │   │   Function: train_lgbm_model
    │   │   │   │   Function: predict_movement_lgbm
    │   │   │   ├── price_predictor_lstm.py
    │   │   │   │   Imports:
    │   │   │   │     - config.paths.PATHS
    │   │   │   │     - core.data_provider.data_provider.load_data
    │   │   │   │     - core.logger.logger.logger
    │   │   │   │     - core.time_context.time_context.get_simulation_date
    │   │   │   │     - datetime.datetime
    │   │   │   │     - db.db_router.insert_dataframe
    │   │   │   │     - joblib
    │   │   │   │     - numpy
    │   │   │   │     - os
    │   │   │   │     - pandas
    │   │   │   │     - predictive_trader.model_manager.load_model_for_date
    │   │   │   │     - sklearn.preprocessing.MinMaxScaler
    │   │   │   │     - tensorflow
    │   │   │   │     - tensorflow.keras.Input
    │   │   │   │     - tensorflow.keras.layers.Dense
    │   │   │   │     - tensorflow.keras.layers.LSTM
    │   │   │   │     - tensorflow.keras.models.Sequential
    │   │   │   │   Function: build_lstm_model
    │   │   │   │   Function: load_price_data
    │   │   │   │   Function: train_lstm_model
    │   │   │   │   Function: predict_next_5days_lstm
    │   │   │   │   Function: save_5day_predictions
    │   │   │   ├── price_predictor_lstm_intraday.py
    │   │   │   │   Imports:
    │   │   │   │     - config.paths.PATHS
    │   │   │   │     - core.data_provider.data_provider.fetch_stock_data
    │   │   │   │     - core.logger.logger.logger
    │   │   │   │     - datetime.time
    │   │   │   │     - joblib
    │   │   │   │     - numpy
    │   │   │   │     - os
    │   │   │   │     - pandas
    │   │   │   │     - sklearn.preprocessing.MinMaxScaler
    │   │   │   │     - tensorflow.keras.Input
    │   │   │   │     - tensorflow.keras.layers.Dense
    │   │   │   │     - tensorflow.keras.layers.LSTM
    │   │   │   │     - tensorflow.keras.models.Sequential
    │   │   │   │     - tensorflow.keras.models.load_model
    │   │   │   │   Function: build_model
    │   │   │   │   Function: train_intraday_model
    │   │   │   │   Function: predict_intraday_return
    │   │   │   ├── price_predictor_lstm_v2.py
    │   │   │   │   Imports:
    │   │   │   │     - config.paths.PATHS
    │   │   │   │     - core.data_provider.data_provider.load_data
    │   │   │   │     - core.logger.logger.logger
    │   │   │   │     - joblib
    │   │   │   │     - numpy
    │   │   │   │     - os
    │   │   │   │     - pandas
    │   │   │   │     - sklearn.preprocessing.MinMaxScaler
    │   │   │   │     - tensorflow.keras.Input
    │   │   │   │     - tensorflow.keras.layers.Dense
    │   │   │   │     - tensorflow.keras.layers.LSTM
    │   │   │   │     - tensorflow.keras.models.Sequential
    │   │   │   │     - tensorflow.keras.models.load_model
    │   │   │   │   Function: build_model
    │   │   │   │   Function: train_lstm_model_v2
    │   │   │   │   Function: predict_5day_return_v2
    │   │   │   └── trade_signal_generator.py
    │   │   │       Imports:
    │   │   │         - core.data_provider.data_provider.fetch_stock_data
    │   │   │         - core.logger.logger.logger
    │   │   │         - datetime.datetime
    │   │   │         - db.db_router.insert_dataframe
    │   │   │         - os
    │   │   │         - pandas
    │   │   │         - predictive_trader.price_predictor_lgbm.predict_movement_lgbm
    │   │   │         - predictive_trader.price_predictor_lstm.predict_next_close_lstm
    │   │   │         - predictive_trader.price_predictor_lstm.predict_next_n_days_lstm
    │   │   │       Function: generate_trade_signal
    │   │   │       Function: generate_signals_for_list
    │   │   ├── rl_strategy_agent.py
    │   │   │   Imports:
    │   │   │     - core.logger.logger.logger
    │   │   │     - core.predict.rl_predictor.load_policy
    │   │   │     - core.predict.rl_predictor.load_rl_frame
    │   │   │     - core.time_context.time_context.get_simulation_date
    │   │   │     - numpy
    │   │   │     - pandas
    │   │   │     - rl.envs.trading_env.TradingEnv
    │   │   │     - stable_baselines3.common.vec_env.DummyVecEnv
    │   │   │   Class: RLStrategyAgent
    │   │   │     Methods:
    │   │   │       - __init__
    │   │   │       - _evaluate_reward
    │   │   │       - evaluate
    │   │   ├── strategy_agent.py
    │   │   │   Imports:
    │   │   │     - core.config.config.settings
    │   │   │     - core.data_provider.data_provider.load_data
    │   │   │     - core.feature_engineering.feature_enricher_multi.enrich_multi_interval_features
    │   │   │     - core.logger.logger.logger
    │   │   │     - core.predict.predictor.predict_dual_model
    │   │   │     - core.replay.replay_logger.log_replay_row
    │   │   │     - core.time_context.time_context.get_simulation_date
    │   │   │     - datetime.datetime
    │   │   │     - db.db.SessionLocal
    │   │   │     - db.models.StockFeatureDay
    │   │   │     - pandas
    │   │   │     - sqlalchemy.orm.Session
    │   │   │   Class: StrategyAgent
    │   │   │     Methods:
    │   │   │       - __init__
    │   │   │       - fetch_features
    │   │   │       - evaluate
    │   │   │       - log_summary
    │   │   └── strategy_agent_old.py
    │   │       Imports:
    │   │         - agents.strategy.rl_strategy_agent.RLStrategyAgent
    │   │         - agents.time_series_agent.TimeSeriesAgent
    │   │         - core.config.config.settings
    │   │         - core.data_provider.data_provider.load_data
    │   │         - core.feature_engineering.feature_enricher_multi.enrich_multi_interval_features
    │   │         - core.logger.logger.logger
    │   │         - core.model_io.load_model
    │   │         - core.predict.predict_entry_exit_config.predict_entry_exit_config
    │   │         - core.predict.predictor.predict_dual_model
    │   │         - core.replay.replay_logger.log_replay_row
    │   │         - core.skiplist.skiplist.add_to_skiplist
    │   │         - core.time_context.time_context.get_simulation_date
    │   │         - datetime.datetime
    │   │         - db.db.SessionLocal
    │   │         - db.models.ParamModelPrediction
    │   │         - db.models.StockFeatureDay
    │   │         - pandas
    │   │         - random
    │   │         - sqlalchemy.orm.Session
    │   │         - traceback
    │   │       Class: StrategyAgent
    │   │         Methods:
    │   │           - __init__
    │   │           - fetch_features
    │   │           - evaluate
    │   │           - _handle_grid_fallback
    │   │           - log_summary
    │   │       Function: is_valid_for_model
    │   └── time_series_agent.py
    │       Imports:
    │         - core.config.config.settings
    │         - core.data_provider.data_provider.load_data
    │         - core.logger.logger.logger
    │         - core.model_io.load_model
    │         - core.model_io.save_model
    │         - datetime.timedelta
    │         - numpy
    │         - pandas
    │         - pmdarima.arima.ARIMA
    │         - traceback
    │         - warnings
    │       Class: TimeSeriesAgent
    │         Methods:
    │           - __init__
    │           - _get_hist
    │           - train_and_store
    │           - predict
    │       Function: warning_to_log
    ├── analysis
    │   └── joint_policy_comparator.py
    │       Imports:
    │         - core.data_provider.data_provider.load_data
    │         - core.logger.logger.logger
    │         - core.time_context.time_context.get_simulation_date
    │         - pandas
    │       Function: compare_joint_policy_vs_rf
    │       Function: classify
    ├── backfill_log.txt
    ├── cache
    │   📄 Skipped 1 data files (.csv, .json, .pyc)
    │   └── fundamentals
    ├── checkpoints
    │   └── ppo.pt
    ├── config
    │   📄 Skipped 2 data files (.csv, .json, .pyc)
    │   ├── paths.py
    │   │   Imports:
    │   │     - pathlib.Path
    │   ├── sql_tables.py
    │   └── system_config.py
    ├── core
    │   ├── __init__.py
    │   ├── backtest_bt.py
    │   │   Imports:
    │   │     - backtesting.Backtest
    │   │     - backtesting.Strategy
    │   │     - backtesting.lib.crossover
    │   │     - core.config.config.settings
    │   │     - core.config.strategy_config.ExitRule
    │   │     - core.config.strategy_config.StrategyConfig
    │   │     - core.data_provider.data_provider.fetch_stock_data
    │   │     - pandas
    │   │   Class: SMA_RSI_Exit
    │   │     Methods:
    │   │       - init
    │   │       - next
    │   │   Function: ta_sma
    │   │   Function: ta_rsi
    │   │   Function: run_backtest_config
    │   ├── config
    │   │   ├── config.py
    │   │   │   Imports:
    │   │   │     - pathlib.Path
    │   │   │     - pydantic.BaseModel
    │   │   │     - pydantic.Field
    │   │   │     - pydantic.SecretStr
    │   │   │     - pydantic_settings.BaseSettings
    │   │   │     - typing.ClassVar
    │   │   │     - typing.Dict
    │   │   │     - typing.List
    │   │   │     - typing.Optional
    │   │   │     - typing.Tuple
    │   │   │   Class: RetrainConfig
    │   │   │   Class: Settings
    │   │   │   Class: Config
    │   │   │   Function: get_feature_columns
    │   │   └── strategy_config.py
    │   │       Imports:
    │   │         - pydantic.BaseModel
    │   │         - typing.Literal
    │   │         - typing.Optional
    │   │       Class: ExitRule
    │   │       Class: StrategyConfig
    │   ├── data_provider
    │   │   ├── data
    │   │   │   📄 Skipped 1 data files (.csv, .json, .pyc)
    │   │   ├── data_cleaner.py
    │   │   │   Imports:
    │   │   │     - core.logger.logger.logger
    │   │   │     - pandas
    │   │   │   Function: normalize_columns
    │   │   │   Function: sanity_check_features
    │   │   ├── data_initializer.py
    │   │   │   Imports:
    │   │   │     - core.data_provider.data_provider.fetch_stock_data
    │   │   │     - core.logger.logger.logger
    │   │   │     - db.conflict_utils.insert_with_conflict_handling
    │   │   │     - db.postgres_manager.read_table
    │   │   │     - integrations.zerodha_fetcher.fetch_historical_data
    │   │   │     - os
    │   │   │     - pandas
    │   │   │   Function: ensure_price_history_prefilled
    │   │   │     Docstring:
    │   │   │       Ensures price history is populated in SQL for selected stocks in
    │   │   │       stock_fundamentals. Uses whitelist if provided. Skips if enough data
    │   │   │       is already present.
    │   │   ├── data_provider.py
    │   │   │   Imports:
    │   │   │     - core.config.config.settings
    │   │   │     - core.data_provider.downsample.downsample_ohlcv
    │   │   │     - core.logger.logger.logger
    │   │   │     - datetime.datetime
    │   │   │     - datetime.timedelta
    │   │   │     - db.conflict_utils.insert_with_conflict_handling
    │   │   │     - db.db.SessionLocal
    │   │   │     - db.db.engine
    │   │   │     - db.models.Base
    │   │   │     - db.models.Instrument
    │   │   │     - db.models.MLSelectedStock
    │   │   │     - db.models.OpenPosition
    │   │   │     - db.models.PaperTrade
    │   │   │     - db.models.Recommendation
    │   │   │     - db.models.SkiplistStock
    │   │   │     - db.models.StockEncoding
    │   │   │     - db.models.StockFeature15m
    │   │   │     - db.models.StockFeature1m
    │   │   │     - db.models.StockFeature60m
    │   │   │     - db.models.StockFeatureDay
    │   │   │     - db.models.StockFundamental
    │   │   │     - db.models.StockPriceHistory
    │   │   │     - integrations.zerodha_fetcher.fetch_historical_data
    │   │   │     - pandas
    │   │   │     - pytz.timezone
    │   │   │     - sqlalchemy.inspect
    │   │   │     - typing.Any
    │   │   │     - typing.List
    │   │   │     - typing.Optional
    │   │   │     - utils.time_utils.to_naive_utc
    │   │   │   Function: fetch_stock_data
    │   │   │   Function: save_data
    │   │   │   Function: load_data
    │   │   │   Function: get_last_close
    │   │   │   Function: delete_cached_features
    │   │   │   Function: list_partitions
    │   │   │   Function: ensure_price_table
    │   │   │   Function: cache_price
    │   │   ├── downsample.py
    │   │   │   Imports:
    │   │   │     - pandas
    │   │   │     - typing.Dict
    │   │   │   Function: downsample_ohlcv
    │   │   ├── fundamentals
    │   │   │   📄 Skipped 2 data files (.csv, .json, .pyc)
    │   │   │   └── fundamental_data_extractor.py
    │   │   │       Imports:
    │   │   │         - core.data_provider.data_provider.load_data
    │   │   │         - core.data_provider.data_provider.save_data
    │   │   │         - core.logger.logger.logger
    │   │   │         - pandas
    │   │   │       Function: load_backup_and_save
    │   │   │       Function: fetch_all
    │   │   ├── live
    │   │   │   ├── bar_generator.py
    │   │   │   │   Imports:
    │   │   │   │     - core.logger.logger.logger
    │   │   │   │     - datetime.datetime
    │   │   │   │     - json
    │   │   │   │     - os
    │   │   │   │     - pandas
    │   │   │   │     - pytz.timezone
    │   │   │   │     - redis
    │   │   │   │     - time
    │   │   │   │   Function: get_ticks
    │   │   │   │   Function: build_ohlcv
    │   │   │   │   Function: enqueue_feature_task
    │   │   │   │   Function: main
    │   │   │   └── tick_collector_redis.py
    │   │   │       Imports:
    │   │   │         - datetime.datetime
    │   │   │         - json
    │   │   │         - kiteconnect.KiteTicker
    │   │   │         - os
    │   │   │         - pytz.timezone
    │   │   │         - redis
    │   │   │       Function: on_ticks
    │   │   │       Function: on_connect
    │   │   │       Function: on_close
    │   │   │       Function: on_error
    │   │   │       Function: main
    │   │   ├── processing
    │   │   │   └── data_pipeline
    │   │   │       └── zerodha_to_postgres.py
    │   │   │           Imports:
    │   │   │             - core.data_provider.data_provider.load_data
    │   │   │             - core.data_provider.data_provider.save_data
    │   │   │             - core.logger.logger.logger
    │   │   │             - datetime.datetime
    │   │   │             - datetime.timedelta
    │   │   │             - db.postgres_manager.run_query
    │   │   │             - integrations.zerodha_fetcher.fetch_historical_data
    │   │   │             - os
    │   │   │             - pandas
    │   │   │             - time
    │   │   │           Function: load_stock_list
    │   │   │           Function: fetch_and_save_stock
    │   │   │           Function: main
    │   │   └── symbols.py
    │   │       Imports:
    │   │         - core.logger.logger.logger
    │   │         - core.skiplist.skiplist.get_skiplist
    │   │         - db.postgres_manager.get_all_symbols
    │   │       Function: get_usable_symbols
    │   ├── event_bus.py
    │   │   Imports:
    │   │     - datetime.datetime
    │   │     - json
    │   │     - redis
    │   │   Function: publish_event
    │   │   Function: subscribe_to_events
    │   ├── feature_engineering
    │   │   ├── backfill_features_from_existing_prices.py
    │   │   │   Imports:
    │   │   │     - concurrent.futures.ThreadPoolExecutor
    │   │   │     - concurrent.futures.as_completed
    │   │   │     - core.config.config.settings
    │   │   │     - core.feature_engineering.feature_provider.fetch_features_with_backfill
    │   │   │     - core.logger.logger.logger
    │   │   │     - db.postgres_manager.get_all_symbols
    │   │   │     - logging
    │   │   │     - os
    │   │   │     - tqdm.tqdm
    │   │   │   Function: backfill
    │   │   ├── feature_backfill_utils.py
    │   │   │   Imports:
    │   │   │     - core.feature_engineering.feature_provider.fetch_features
    │   │   │     - redis_worker.redis_utils.enqueue_feature_backfill
    │   │   │     - redis_worker.redis_utils.wait_for_feature_ready
    │   │   │   Function: fetch_features_with_backfill
    │   │   │     Docstring:
    │   │   │       Wrapper that ensures features are computed via Redis before fetching
    │   │   │       them.
    │   │   ├── feature_computer.py
    │   │   │   Imports:
    │   │   │     - core.data_provider.data_provider.fetch_stock_data
    │   │   │     - core.feature_engineering.precompute_features.compute_features
    │   │   │     - core.logger.logger.logger
    │   │   │     - pandas
    │   │   │   Function: compute_and_prepare_features
    │   │   ├── feature_enricher.py
    │   │   │   Imports:
    │   │   │     - core.config.config.settings
    │   │   │     - core.logger.logger.logger
    │   │   │     - datetime.datetime
    │   │   │     - db.db.SessionLocal
    │   │   │     - pandas
    │   │   │     - sqlalchemy.sql.text
    │   │   │     - utils.time_utils.to_naive_utc
    │   │   │   Function: enrich_features
    │   │   ├── feature_enricher_multi.py
    │   │   │   Imports:
    │   │   │     - core.feature_engineering.feature_enricher.enrich_features
    │   │   │     - datetime.datetime
    │   │   │     - pandas
    │   │   │   Function: enrich_multi_interval_features
    │   │   ├── feature_provider.py
    │   │   │   Imports:
    │   │   │     - core.config.config.settings
    │   │   │     - core.feature_engineering.regime_features.compute_regime_features
    │   │   │     - core.feature_store.feature_store.get_or_compute
    │   │   │     - core.logger.logger.logger
    │   │   │     - core.skiplist.skiplist.is_in_skiplist
    │   │   │     - datetime.datetime
    │   │   │     - pandas
    │   │   │   Function: fetch_features
    │   │   │     Docstring:
    │   │   │       Unified interface to fetch features using DuckDB-backed cache.  Args:
    │   │   │       stock (str): stock symbol     interval (str): time interval (e.g.
    │   │   │       'day', '15minute')     refresh_if_missing (bool): whether to compute
    │   │   │       if missing     start (str or datetime): optional start date     end
    │   │   │       (str or datetime): optional end date  Returns:     pd.DataFrame with
    │   │   │       feature rows (can be empty)
    │   │   │   Function: fetch_features_with_backfill
    │   │   │     Docstring:
    │   │   │       Backward-compatible fetch with fallback, used in simulation mode.
    │   │   ├── feature_provider_old.py
    │   │   │   Imports:
    │   │   │     - core.config.config.settings
    │   │   │     - core.data_provider.data_provider.fetch_stock_data
    │   │   │     - core.data_provider.data_provider.load_data
    │   │   │     - core.feature_engineering.precompute_features.compute_features
    │   │   │     - core.feature_engineering.precompute_features.insert_feature_row
    │   │   │     - core.logger.logger.logger
    │   │   │     - core.skiplist.skiplist.is_in_skiplist
    │   │   │     - datetime.datetime
    │   │   │     - datetime.timedelta
    │   │   │     - db.db.SessionLocal
    │   │   │     - pandas
    │   │   │     - sqlalchemy.sql.text
    │   │   │   Function: process_and_insert
    │   │   │   Function: fetch_features
    │   │   │   Function: fetch_features_with_backfill
    │   │   ├── precompute_features.py
    │   │   │   Imports:
    │   │   │     - argparse
    │   │   │     - core.config.config.settings
    │   │   │     - core.data_provider.data_provider.fetch_stock_data
    │   │   │     - core.logger.logger.logger
    │   │   │     - core.time_context.time_context.get_stock_universe
    │   │   │     - datetime.datetime
    │   │   │     - datetime.timedelta
    │   │   │     - db.db.SessionLocal
    │   │   │     - pandas
    │   │   │     - sqlalchemy.sql.text
    │   │   │     - ta
    │   │   │     - utils.time_utils.to_naive_utc
    │   │   │   Function: compute_features
    │   │   │   Function: insert_feature_row
    │   │   │   Function: enrich_and_store
    │   │   └── regime_features.py
    │   │       Imports:
    │   │         - numpy
    │   │         - pandas
    │   │       Function: compute_regime_features
    │   │         Docstring:
    │   │           Compute volatility and trend signals to classify market regime.
    │   │           Returns a DataFrame with added regime tag columns.
    │   │       Function: classify_regime
    │   ├── feature_store
    │   │   └── feature_store.py
    │   │       Imports:
    │   │         - core.feature_engineering.feature_computer.compute_and_prepare_features
    │   │         - core.logger.logger.logger
    │   │         - core.time_context.time_context.get_simulation_date
    │   │         - duckdb
    │   │         - os
    │   │         - pandas
    │   │       Function: get_cached_features
    │   │       Function: insert_features
    │   │       Function: get_or_compute
    │   ├── logger
    │   │   ├── logger.py
    │   │   │   Imports:
    │   │   │     - core.config.config.settings
    │   │   │     - datetime.datetime
    │   │   │     - logging
    │   │   │     - os
    │   │   │     - re
    │   │   │     - sys
    │   │   │   Class: SafeFormatter
    │   │   │     Methods:
    │   │   │       - format
    │   │   │   Function: strip_surrogates
    │   │   │   Function: success
    │   │   │   Function: warnings
    │   │   │   Function: errors
    │   │   │   Function: start
    │   │   └── system_logger.py
    │   │       Imports:
    │   │         - core.logger.logger.logger
    │   │         - core.time_context.time_context.get_simulation_date
    │   │         - datetime.datetime
    │   │         - db.postgres_manager.insert_dataframe
    │   │         - db.postgres_manager.run_query
    │   │         - json
    │   │         - pandas
    │   │       Function: log_event
    │   ├── model_io.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.logger.logger.logger
    │   │     - datetime.datetime
    │   │     - db.conflict_utils.insert_with_conflict_handling
    │   │     - db.postgres_manager.run_query
    │   │     - pandas
    │   │     - pickle
    │   │   Function: save_model
    │   │     Docstring:
    │   │       Serialize and save a model to the configured SQL table with optional
    │   │       metadata.
    │   │   Function: load_model
    │   │   Function: get_model_metadata
    │   │   Function: load_latest_model
    │   │     Docstring:
    │   │       Loads the most recent model from model_store that matches base_name
    │   │       prefix.
    │   ├── notifications
    │   │   └── redis_notifier.py
    │   │       Imports:
    │   │         - redis.Redis
    │   │       Function: push_feature_ready
    │   │         Docstring:
    │   │           Push a symbol to the Redis queue to signal that features are ready.
    │   ├── policy
    │   │   ├── __init__.py
    │   │   │   Imports:
    │   │   │     - core.logger.logger.logger
    │   │   │     - core.policy.rl_policy.RLPolicyModel
    │   │   │     - core.system_state.get_system_config
    │   │   │     - models.joint_policy.JointPolicyModel
    │   │   │     - pandas
    │   │   │   Function: choose_policy_model
    │   │   ├── rl_policy.py
    │   │   │   Imports:
    │   │   │     - core.logger.logger.logger
    │   │   │     - os
    │   │   │     - pandas
    │   │   │     - torch
    │   │   │   Class: RLPolicyModel
    │   │   │     Methods:
    │   │   │       - __init__
    │   │   │       - load
    │   │   │       - predict
    │   │   └── train_joint_from_replay.py
    │   │       Imports:
    │   │         - core.logger.logger.logger
    │   │         - core.model_io.save_model
    │   │         - core.time_context.time_context.get_simulation_date
    │   │         - db.postgres_manager.run_query
    │   │         - json
    │   │         - models.joint_policy.JointPolicyModel
    │   │         - pandas
    │   │       Function: load_replay_data
    │   │       Function: main
    │   ├── predict
    │   │   ├── grid_predictor.py
    │   │   │   Imports:
    │   │   │     - backtesting.backtesting
    │   │   │     - core.backtest_bt.run_backtest_config
    │   │   │     - core.config.strategy_config.ExitRule
    │   │   │     - core.config.strategy_config.StrategyConfig
    │   │   │     - core.data_provider.data_provider.fetch_stock_data
    │   │   │     - core.logger.logger.logger
    │   │   │     - core.time_context.time_context.get_simulation_date
    │   │   │     - datetime.datetime
    │   │   │     - db.postgres_manager.run_query
    │   │   │     - json
    │   │   │     - multiprocessing
    │   │   │     - pandas
    │   │   │   Function: predict_grid_config
    │   │   │   Function: persist_grid_recommendations
    │   │   ├── policy_chooser.py
    │   │   │   Imports:
    │   │   │     - agents.allocator_agent.AllocatorAgent
    │   │   │     - core.logger.logger.logger
    │   │   │     - core.policy.policy_manager.choose_best_policy
    │   │   │     - core.system_state.get_system_config
    │   │   │     - core.system_state.update_system_config
    │   │   │     - core.time_context.time_context.get_simulation_date
    │   │   │     - db.postgres_manager.SessionLocal
    │   │   │     - db.postgres_manager.run_query
    │   │   │     - pandas
    │   │   │     - prefect.flow
    │   │   │     - sqlalchemy.Column
    │   │   │     - sqlalchemy.Date
    │   │   │     - sqlalchemy.Float
    │   │   │     - sqlalchemy.Integer
    │   │   │     - sqlalchemy.JSON
    │   │   │     - sqlalchemy.MetaData
    │   │   │     - sqlalchemy.String
    │   │   │     - sqlalchemy.TIMESTAMP
    │   │   │     - sqlalchemy.Table
    │   │   │     - sqlalchemy.insert
    │   │   │     - sqlalchemy.text
    │   │   │   Function: save_policy_choice
    │   │   │   Function: policy_chooser_flow
    │   │   │   Function: get_sharpe
    │   │   │   Function: policy_chooser
    │   │   │   Function: get_current_allocation
    │   │   │   Function: set_current_allocation
    │   │   ├── ppo_live_policy.py
    │   │   │   Imports:
    │   │   │     - core.feature_store.feature_store.get_or_compute
    │   │   │     - core.logger.logger.logger
    │   │   │     - numpy
    │   │   │     - pandas
    │   │   │     - stable_baselines3.PPO
    │   │   │   Class: PPOLivePolicy
    │   │   │     Methods:
    │   │   │       - __init__
    │   │   │       - predict
    │   │   ├── predict_entry_exit_config.py
    │   │   │   Imports:
    │   │   │     - core.logger.logger.logger
    │   │   │     - core.model_io.load_model
    │   │   │     - numpy
    │   │   │     - pandas
    │   │   │   Function: predict_entry_exit_config
    │   │   ├── predict_param_model.py
    │   │   │   Imports:
    │   │   │     - core.config.config.settings
    │   │   │     - core.logger.logger.logger
    │   │   │     - core.model_io.load_model
    │   │   │     - numpy
    │   │   │     - pandas
    │   │   │   Function: predict_param_config
    │   │   ├── predictor.py
    │   │   │   Imports:
    │   │   │     - core.logger.logger.logger
    │   │   │     - core.time_context.time_context.get_simulation_date
    │   │   │     - models.joint_policy.JointPolicyModel
    │   │   │     - pandas
    │   │   │   Function: predict_dual_model
    │   │   │     Docstring:
    │   │   │       Predicts if a trade should be triggered and its expected return.
    │   │   │       Returns a list of dicts with unified format: [{    "stock": <symbol>,
    │   │   │       "trade_triggered": <0|1>,    "predicted_return": <float>,
    │   │   │       "recommended_config": <dict>,    "model_source": "joint" }]
    │   │   └── rl_predictor.py
    │   │       Imports:
    │   │         - core.config.config.settings
    │   │         - core.data_provider.data_provider.fetch_stock_data
    │   │         - core.data_provider.data_provider.load_data
    │   │         - core.feature_engineering.feature_enricher_multi.enrich_multi_interval_features
    │   │         - core.logger.logger.logger
    │   │         - core.model_io.load_latest_model
    │   │         - core.model_io.load_model
    │   │         - core.time_context.time_context.get_simulation_date
    │   │         - numpy
    │   │         - pandas
    │   │         - rl.envs.trading_env.TradingEnv
    │   │         - stable_baselines3.PPO
    │   │         - stable_baselines3.common.vec_env.DummyVecEnv
    │   │       Function: load_policy
    │   │       Function: load_rl_frame
    │   │       Function: predict_action
    │   │       Function: predict_with_fallback
    │   ├── rl
    │   │   ├── gym_env.py
    │   │   │   Imports:
    │   │   │     - core.feature_store.feature_store.get_or_compute
    │   │   │     - core.logger.logger.logger
    │   │   │     - core.time_context.time_context.get_simulation_date
    │   │   │     - db.postgres_manager.run_query
    │   │   │     - gym
    │   │   │     - gym.spaces
    │   │   │     - numpy
    │   │   │     - pandas
    │   │   │   Class: ODINTradingEnv
    │   │   │     Docstring:
    │   │   │       A custom Gym environment for RL agent in O.D.I.N. Reads replay events
    │   │   │       from SQL replay_buffer and yields observations and rewards.
    │   │   │     Methods:
    │   │   │       - __init__
    │   │   │       - _load_events
    │   │   │       - _parse_event
    │   │   │       - reset
    │   │   │       - step
    │   │   ├── ppo_trainer.py
    │   │   │   Imports:
    │   │   │     - collections.deque
    │   │   │     - core.logger.logger.logger
    │   │   │     - core.rl.gym_env.ODINTradingEnv
    │   │   │     - numpy
    │   │   │     - os
    │   │   │     - torch
    │   │   │     - torch.nn
    │   │   │     - torch.optim.Adam
    │   │   │     - utils.progress_logger.log_model_progress
    │   │   │   Class: ActorCritic
    │   │   │     Methods:
    │   │   │       - __init__
    │   │   │       - forward
    │   │   │   Class: PPOTrainer
    │   │   │     Methods:
    │   │   │       - __init__
    │   │   │       - collect_rollout
    │   │   │       - train_step
    │   │   │       - save_model
    │   │   │       - load_model
    │   │   ├── replay_buffer.py
    │   │   │   Imports:
    │   │   │     - collections.deque
    │   │   │     - core.logger.logger.logger
    │   │   │     - core.time_context.time_context.get_simulation_date
    │   │   │     - datetime.datetime
    │   │   │     - db.postgres_manager.insert_rows
    │   │   │     - json
    │   │   │     - pandas
    │   │   │   Class: ReplayBuffer
    │   │   │     Methods:
    │   │   │       - __init__
    │   │   │       - add
    │   │   │       - flush_to_sql
    │   │   └── sql_env.py
    │   │       Imports:
    │   │         - core.feature_store.feature_store.get_or_compute
    │   │         - core.logger.logger.logger
    │   │         - core.time_context.time_context.get_simulation_date
    │   │         - db.postgres_manager.run_query
    │   │         - gym
    │   │         - gym.spaces
    │   │         - numpy
    │   │         - pandas
    │   │       Class: ODINSQLTradingEnv
    │   │         Docstring:
    │   │           Fallback Gym environment for PPO trainer that pulls replay events from
    │   │           SQL instead of Redis (used when Redis is not running).
    │   │         Methods:
    │   │           - __init__
    │   │           - _load_events
    │   │           - _parse_event
    │   │           - reset
    │   │           - step
    │   ├── skiplist
    │   │   └── skiplist.py
    │   │       Imports:
    │   │         - core.config.config.settings
    │   │         - core.logger.logger.logger
    │   │         - datetime.datetime
    │   │         - datetime.timedelta
    │   │         - db.postgres_manager.run_query
    │   │       Function: is_in_skiplist
    │   │       Function: add_to_skiplist
    │   │       Function: remove_from_skiplist
    │   │       Function: get_skiplist
    │   ├── system_state.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.logger.logger.logger
    │   │     - core.model_io.load_model
    │   │     - core.time_context.time_context.get_simulation_date
    │   │     - datetime.datetime
    │   │     - json
    │   │     - pandas
    │   │   Function: get_market_data_state
    │   │   Function: get_feature_state
    │   │   Function: get_model_state
    │   │   Function: get_planner_state
    │   │   Function: get_execution_state
    │   │   Function: build_system_state
    │   │   Function: get_system_config
    │   │   Function: update_system_config
    │   ├── time_context
    │   │   └── time_context.py
    │   │       Imports:
    │   │         - datetime.datetime
    │   │         - datetime.time
    │   │         - os
    │   │         - pandas
    │   │         - pandas.tseries.offsets.BDay
    │   │         - pytz
    │   │       Function: get_simulation_date
    │   │         Docstring:
    │   │           Return simulation date as timezone-aware pd.Timestamp (IST)
    │   │       Function: set_simulation_date
    │   │       Function: clear_simulation_date
    │   ├── token_manager.py
    │   │   Imports:
    │   │     - json
    │   │     - os
    │   │     - pathlib.Path
    │   │   Function: save_access_token
    │   │   Function: load_access_token
    │   │   Function: get_saved_access_token
    │   └── validation
    │       ├── __init__.py
    │       └── data_checks.py
    │           Imports:
    │             - numpy
    │             - pandas
    │             - scipy.stats.zscore
    │           Function: check_missing
    │           Function: class_balance
    │           Function: detect_outliers
    ├── create_daily_features.sql
    ├── data
    │   └── feature_store.duckdb
    ├── db
    │   ├── __init__.py
    │   ├── conflict_utils.py
    │   │   Imports:
    │   │     - db.db.engine
    │   │     - db.models.Base
    │   │     - pandas
    │   │     - sqlalchemy.dialects.postgresql.insert
    │   │   Function: insert_with_conflict_handling
    │   ├── csv_to_sql.py
    │   │   Imports:
    │   │     - db.db_router.insert_dataframe
    │   │     - pandas
    │   │     - pathlib.Path
    │   │     - sys
    │   │   Function: csv_to_sql
    │   ├── db.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - sqlalchemy.create_engine
    │   │     - sqlalchemy.orm.sessionmaker
    │   │   Function: get_session
    │   │     Docstring:
    │   │       Returns a new SQLAlchemy Session.
    │   ├── init_postgres.py
    │   │   Imports:
    │   │     - db.postgres_manager.execute_raw_sql
    │   │     - db.postgres_manager.run_query
    │   │   Function: table_exists
    │   │   Function: init_postgres
    │   ├── models.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - datetime.date
    │   │     - datetime.datetime
    │   │     - sqlalchemy.BigInteger
    │   │     - sqlalchemy.Boolean
    │   │     - sqlalchemy.Column
    │   │     - sqlalchemy.Date
    │   │     - sqlalchemy.DateTime
    │   │     - sqlalchemy.Float
    │   │     - sqlalchemy.Integer
    │   │     - sqlalchemy.JSON
    │   │     - sqlalchemy.String
    │   │     - sqlalchemy.TIMESTAMP
    │   │     - sqlalchemy.dialects.postgresql.JSONB
    │   │     - sqlalchemy.orm.declarative_base
    │   │   Class: Instrument
    │   │   Class: SkiplistStock
    │   │   Class: StockPriceHistory
    │   │   Class: JointPolicyPrediction
    │   │   Class: StockFeatureDay
    │   │   Class: StockFeature1m
    │   │   Class: StockFeature15m
    │   │   Class: StockFeature60m
    │   │   Class: StockFundamental
    │   │   Class: StockEncoding
    │   │   Class: Recommendation
    │   │   Class: OpenPosition
    │   │   Class: PaperTrade
    │   │   Class: FilterModelPrediction
    │   │   Class: ParamModelPrediction
    │   │   Class: PriceModelPrediction
    │   │   Class: TrainingData
    │   │   Class: SystemLog
    │   │   Class: MLSelectedStock
    │   │     Methods:
    │   │       - __repr__
    │   ├── postgres_manager.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - core.logger.logger.logger
    │   │     - db.db.SessionLocal
    │   │     - db.models.Instrument
    │   │     - db.models.SkiplistStock
    │   │     - pandas
    │   │     - sqlalchemy.create_engine
    │   │     - sqlalchemy.text
    │   │     - typing.List
    │   │   Function: read_table
    │   │   Function: run_query
    │   │   Function: execute_raw_sql
    │   │   Function: insert_dataframe
    │   │     Docstring:
    │   │       Bulk-insert a DataFrame into a PostgreSQL table using SQLAlchemy.
    │   │   Function: get_all_symbols
    │   └── replay_buffer_sql.py
    │       Imports:
    │         - datetime.datetime
    │         - db.postgres_manager.run_query
    │         - json
    │         - pandas
    │       Function: insert_replay_episode
    │       Function: load_replay_episodes
    │       Function: clear_old_episodes
    │       Function: count_by_stock
    ├── diagnosis
    │   ├── clear_all_sql_tables.py
    │   │   Imports:
    │   │     - core.logger.logger.logger
    │   │     - db.db_router.execute_raw_sql
    │   │   Function: clear_all_tables
    │   ├── diagnose_storage.py
    │   │   Imports:
    │   │     - core.data_provider.data_provider.load_data
    │   │     - os
    │   │     - pathlib.Path
    │   │     - sqlite3
    │   │   Function: table_exists
    │   ├── evaluate_model_curves.py
    │   │   Imports:
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.logger.logger.logger
    │   │     - matplotlib.pyplot
    │   │     - numpy
    │   │     - pandas
    │   │     - sklearn.metrics.mean_absolute_error
    │   │     - sklearn.metrics.mean_squared_error
    │   │   Function: load_predictions
    │   │   Function: load_actual_prices
    │   │   Function: evaluate_model
    │   ├── fix_model_path_usage.py
    │   │   Imports:
    │   │     - pathlib.Path
    │   │     - re
    │   │   Function: fix_file
    │   │   Function: main
    │   ├── migrate_paths_to_sql.py
    │   │   Imports:
    │   │     - argparse
    │   │     - os
    │   │     - pathlib.Path
    │   │     - re
    │   │   Function: transform_code
    │   │   Function: update_file
    │   │   Function: run_all
    │   ├── migrate_to_sql.py
    │   │   Imports:
    │   │     - config.paths.PATHS
    │   │     - db.db_router.DB_PATH
    │   │     - db.db_router.insert_dataframe
    │   │     - os
    │   │     - pandas
    │   │     - pickle
    │   │     - sqlite3
    │   │   Function: ensure_blob_json_tables
    │   │     Docstring:
    │   │       Create the blob and JSON store tables if they don't exist.
    │   │   Function: migrate_csv
    │   │   Function: migrate_pkl
    │   │   Function: migrate_json
    │   │   Function: migrate_to_sql
    │   ├── seed_training_data.py
    │   │   Imports:
    │   │     - core.logger.logger.logger
    │   │     - db.db_router.insert_dataframe
    │   │     - pandas
    │   │   Function: seed
    │   ├── simulate_execution.py
    │   │   Imports:
    │   │     - agents.execution.execution_agent_sql.ExecutionAgentSQL
    │   │     - core.logger.logger.logger
    │   │     - core.time_context.time_context.clear_simulation_date
    │   │     - core.time_context.time_context.set_simulation_date
    │   │     - datetime.datetime
    │   │     - datetime.timedelta
    │   │     - predictive_trader.curve_predictor.generate_curves_for_list
    │   │     - predictive_trader.curve_signal_generator.generate_signals_from_curves
    │   │   Function: generate_trading_days
    │   │   Function: simulate_trading_days
    │   ├── simulate_history.py
    │   │   Imports:
    │   │     - agents.memory.memory_agent.MemoryAgent
    │   │     - agents.planner.intraday_planner_agent.IntradayPlannerAgent
    │   │     - agents.planner.planner_agent_sql.PlannerAgentSQL
    │   │     - argparse
    │   │     - core.logger.logger.logger
    │   │     - core.time_context.time_context.set_simulation_date
    │   │     - datetime.datetime
    │   │     - models.meta_strategy_selector.train_meta_model
    │   │     - models.train_dual_model_sql.train_dual_model
    │   │     - models.train_exit_model.train_exit_model
    │   │     - models.train_param_model.train_param_model
    │   │     - models.train_stock_filter_model.train_stock_filter_model
    │   │     - pandas
    │   │     - subprocess
    │   │   Function: daterange
    │   │   Function: simulate_and_bootstrap
    │   ├── simulate_history_single.py
    │   │   Imports:
    │   │     - agents.planner.planner_agent_sql.PlannerAgentSQL
    │   │     - argparse
    │   │     - core.logger.logger.logger
    │   │     - core.time_context.time_context.set_simulation_date
    │   │     - datetime.datetime
    │   │     - datetime.timedelta
    │   │     - pandas
    │   │   Function: simulate_stock_over_range
    │   └── view_predicted_curves.py
    │       Imports:
    │         - core.data_provider.data_provider.load_data
    │         - core.logger.logger.logger
    │         - matplotlib.pyplot
    │         - numpy
    │         - pandas
    │         - sklearn.metrics.mean_absolute_error
    │         - sklearn.metrics.mean_squared_error
    │       Function: load_predictions
    │       Function: load_actual_prices
    │       Function: evaluate_model
    ├── docker-compose.yml
    ├── flows
    │   ├── attribution_flow.py
    │   │   Imports:
    │   │     - core.event_bus.emit_event
    │   │     - core.logger.logger.logger
    │   │     - core.time_context.time_context.get_simulation_date
    │   │     - db.postgres_manager.run_query
    │   │     - pandas
    │   │     - prefect.flow
    │   │   Function: reward_attribution_flow
    │   ├── auto_pipeline.py
    │   │   Imports:
    │   │     - agents.memory.feedback_loop.update_training_data
    │   │     - agents.memory.memory_agent.MemoryAgent
    │   │     - archive.feature_enricher.enrich_features
    │   │     - argparse
    │   │     - core.backtest_bt.run_backtest
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.fetch_stock_data
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.data_provider.data_provider.save_data
    │   │     - datetime.date
    │   │     - datetime.timedelta
    │   │     - db.db.get_session
    │   │     - models.meta_strategy_selector.train_meta_model
    │   │     - models.stock_filter_predictor.run_stock_filter
    │   │     - models.train_dual_model_sql.train_dual_model
    │   │     - models.train_stock_filter_model.train_stock_filter_model
    │   │     - prefect.flow
    │   │     - prefect.get_run_logger
    │   │     - prefect.server.schemas.schedules.IntervalSchedule
    │   │     - prefect.task
    │   │     - sqlalchemy.text
    │   │   Function: get_last_date
    │   │   Function: update_last_date
    │   │   Function: ingest_data
    │   │   Function: enrich
    │   │   Function: run_filter
    │   │   Function: backtest_and_label
    │   │   Function: check_drift_and_trigger
    │   │   Function: retrain_models
    │   │   Function: self_learning_pipeline
    │   ├── backfill_1m_features_flow.py
    │   │   Imports:
    │   │     - core.data_provider.data_provider.fetch_stock_data
    │   │     - core.data_provider.data_provider.save_data
    │   │     - core.feature_engineering.feature_enricher_multi.enrich_multi_interval_features
    │   │     - core.logger.logger.logger
    │   │     - core.notifications.redis_notifier.push_feature_ready
    │   │     - core.time_context.time_context.get_simulation_date
    │   │     - datetime.datetime
    │   │     - datetime.timedelta
    │   │     - db.postgres_manager.get_all_symbols
    │   │     - pandas
    │   │     - prefect.flow
    │   │     - prefect.get_run_logger
    │   │     - prefect.task
    │   │   Function: backfill_for_symbol
    │   │   Function: backfill_1m_feature_flow
    │   ├── backfill_pipeline.py
    │   │   Imports:
    │   │     - argparse
    │   │     - datetime.date
    │   │     - datetime.timedelta
    │   │     - flows.auto_pipeline.self_learning_pipeline
    │   │     - prefect.flow
    │   │   Function: historical_backfill
    │   ├── bootstrap
    │   ├── fundamental_pipeline.py
    │   │   Imports:
    │   │     - argparse
    │   │     - bs4.BeautifulSoup
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.data_provider.data_provider.save_data
    │   │     - core.logger.logger.logger
    │   │     - core.skiplist.skiplist.add_to_skiplist
    │   │     - core.skiplist.skiplist.is_in_skiplist
    │   │     - db.postgres_manager.run_query
    │   │     - numpy
    │   │     - os
    │   │     - pandas
    │   │     - pathlib.Path
    │   │     - prefect.flow
    │   │     - prefect.get_run_logger
    │   │     - prefect.task
    │   │     - requests
    │   │     - time
    │   │     - yfinance
    │   │   Function: load_nse_symbols
    │   │   Function: is_cache_valid
    │   │   Function: save_local_cache
    │   │   Function: clear_sql_table
    │   │   Function: clear_local_cache
    │   │   Function: _scrape_screener
    │   │   Function: _fetch_yfinance
    │   │   Function: fetch_fundamentals
    │   │   Function: parse_fundamentals
    │   │   Function: clear_everything
    │   │   Function: get_todo_symbols
    │   │   Function: fetch_one
    │   │   Function: save_batch
    │   │   Function: fundamental_fetch_flow
    │   │     Docstring:
    │   │       1) Optionally clear out everything if --force 2) Figure out which
    │   │       symbols still need data 3) Fan out one task per symbol (up to your
    │   │       concurrency limit) 4) Persist the successful rows back into SQL 5) On
    │   │       subsequent Prefect runs you’ll only fetch the delta    until
    │   │       “get_todo_symbols” returns empty → you’re done.
    │   ├── live
    │   ├── log_feedback_transitions_flow.py
    │   │   Imports:
    │   │     - core.event_bus.subscribe_to_events
    │   │     - core.logger.logger.logger
    │   │     - db.replay_buffer_sql.insert_replay_episode
    │   │     - prefect.flow
    │   │   Function: handle_trade_close
    │   │   Function: feedback_logger_flow
    │   ├── monitor_system_flow.py
    │   │   Imports:
    │   │     - core.logger.logger.logger
    │   │     - core.predict.policy_chooser.get_sharpe
    │   │     - core.system_state.get_system_config
    │   │     - core.time_context.time_context.get_simulation_date
    │   │     - db.postgres_manager.insert_row
    │   │     - db.postgres_manager.run_query
    │   │     - json
    │   │     - pandas
    │   │     - prefect.flow
    │   │   Function: monitor_system_flow
    │   │   Function: _get_reward_summary
    │   │   Function: _get_training_summary
    │   ├── retrain
    │   ├── schedule_precompute_features.py
    │   │   Imports:
    │   │     - core.logger.logger.logger
    │   │     - prefect.flow
    │   │     - prefect.task
    │   │     - subprocess
    │   │   Function: run_precompute
    │   │   Function: precompute_features_flow
    │   ├── track_replay_summary_flow.py
    │   │   Imports:
    │   │     - core.logger.logger.logger
    │   │     - core.time_context.time_context.get_simulation_date
    │   │     - db.postgres_manager.insert_df
    │   │     - db.postgres_manager.run_query
    │   │     - pandas
    │   │     - prefect.flow
    │   │   Function: track_replay_summary_flow
    │   ├── trading_pipeline.py
    │   │   Imports:
    │   │     - core.data_provider.data_provider.load_data
    │   │     - datetime.date
    │   │     - db.postgres_manager.run_query
    │   │     - optuna
    │   │     - pandas
    │   │     - prefect.deployments.Deployment
    │   │     - prefect.flow
    │   │     - prefect.server.schemas.schedules.CronSchedule
    │   │     - prefect.task
    │   │     - vectorbt
    │   │   Class: FeatureBuilder
    │   │     Methods:
    │   │       - __init__
    │   │       - build
    │   │   Class: SignalGenerator
    │   │     Methods:
    │   │       - __init__
    │   │       - generate
    │   │   Function: task_fetch_price
    │   │   Function: task_persist_signals
    │   │   Function: task_execute
    │   │   Function: optimize_strategy
    │   │   Function: daily_trading_flow
    │   │   Function: objective
    │   ├── train_joint_policy_flow.py
    │   │   Imports:
    │   │     - agents.joint_policy_trainer.train_joint_policy_if_ready
    │   │     - core.logger.logger.logger
    │   │     - prefect.flow
    │   │   Function: train_joint_policy_flow
    │   ├── train_rl_policy_flow.py
    │   │   Imports:
    │   │     - agents.rl_ppo_trainer.retrain_ppo_if_ready
    │   │     - core.logger.logger.logger
    │   │     - prefect.flow
    │   │   Function: train_rl_policy_flow
    │   └── update_rl_rewards_flow.py
    │       Imports:
    │         - core.logger.logger.logger
    │         - core.time_context.time_context.get_simulation_date
    │         - db.postgres_manager.run_query
    │         - prefect.flow
    │       Function: update_rl_rewards_flow
    ├── generate_project_summary.py
    │   Imports:
    │     - argparse
    │     - ast
    │     - collections.Counter
    │     - collections.defaultdict
    │     - hashlib
    │     - json
    │     - os
    │     - re
    │     - time
    │   Function: attach_parents
    │   Function: compute_cyclomatic_complexity
    │   Function: get_docstring_coverage
    │   Function: get_missing_docstrings
    │   Function: hash_file_contents
    │   Function: get_priority
    │   Function: infer_category_and_subsystem
    │   Function: extract_model_names_from_calls
    │   Function: extract_intervals_and_db_tables
    │   Function: detect_metrics_used
    │   Function: scan_project
    │   Function: main
    │   Function: extract_data_flow_info
    │   Function: parse_python_file
    │   Function: extract_additional_data_signals
    ├── generate_project_summary_txt.py
    │   Imports:
    │     - argparse
    │     - ast
    │     - os
    │     - textwrap
    │   Class: SimpleLogger
    │     Methods:
    │       - info
    │   Function: parse_python_file
    │     Docstring:
    │       Parses a Python file to extract imports, classes (with methods and
    │       docstrings), and functions (with docstrings).  Args:     filepath
    │       (str): The path to the Python file.  Returns:     dict: A dictionary
    │       containing parsed information (imports, classes, functions).
    │       Returns an empty dictionary if the file cannot be read or parsed.
    │   Function: attach_parents
    │     Docstring:
    │       Recursively attaches a 'parent' attribute to each node in the AST,
    │       pointing to its parent node. This is useful for contextual analysis.
    │   Function: extract_data_access_summary
    │     Docstring:
    │       Extracts summary of data access points (e.g., calls to 'load_data',
    │       'save_data') from Python files within the given path.  Args:     path
    │       (str): The root directory to search for Python files.  Returns:
    │       list: A list of tuples, where each tuple contains (filepath,
    │       data_access_call_string).
    │   Function: build_tree_and_extract
    │     Docstring:
    │       Recursively builds a tree-like representation of the project
    │       structure, extracting and displaying details for Python files
    │       (imports, classes, functions, docstrings).  Args:     path (str): The
    │       current path (file or directory).     prefix (str): The prefix string
    │       for indentation in the tree.     is_last (bool): True if the current
    │       item is the last sibling in its directory.  Returns:     list: A list
    │       of strings, each representing a line in the project summary.
    │   Function: main
    │     Docstring:
    │       Main function to parse command-line arguments, build the project
    │       summary, and write it to an output file.
    │   Function: parse_with_parent
    ├── generate_stock_labels.py
    │   Imports:
    │     - core.logger.logger.logger
    │     - os
    │     - pandas
    │   Function: generate_labels
    ├── generate_training_data.py
    │   Imports:
    │     - core.logger.logger.logger
    │     - os
    │     - pandas
    │   Function: main
    ├── integrations
    │   ├── __init__.py
    │   ├── drift_detection.py
    │   │   Imports:
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.logger.logger.logger
    │   │     - evidently.metric_preset.DataDriftPreset
    │   │     - evidently.report.Report
    │   │   Function: check_drift
    │   ├── zerodha_client.py
    │   │   Imports:
    │   │     - json
    │   │     - kiteconnect.KiteConnect
    │   │     - kiteconnect.KiteTicker
    │   │     - os
    │   │   Function: get_kite
    │   │   Function: get_ticker
    │   └── zerodha_fetcher.py
    │       Imports:
    │         - core.logger.logger.logger
    │         - datetime.datetime
    │         - datetime.timedelta
    │         - dateutil.parser.parse
    │         - db.conflict_utils.insert_with_conflict_handling
    │         - db.postgres_manager.run_query
    │         - integrations.zerodha_client.get_kite
    │         - os
    │         - pandas
    │         - utils.time_utils.to_naive_utc
    │       Function: get_last_trading_day
    │       Function: is_valid_price_df
    │       Function: fetch_historical_data
    │       Function: get_instrument_token
    │       Function: main
    ├── jobs
    │   └── recheck_expired_skips.py
    │       Imports:
    │         - core.logger.logger.logger
    │         - core.skiplist.skiplist.remove_from_skiplist
    │         - datetime.datetime
    │         - db.postgres_manager.run_query
    │       Function: recheck_stock
    │         Docstring:
    │           Placeholder for actual recheck logic. Currently assumes recheck always
    │           succeeds. Replace with fetch or retry logic.
    │       Function: run_expired_skip_recheck
    ├── logs
    │   📄 Skipped 1 data files (.csv, .json, .pyc)
    │   ├── history_simulation
    │   │   └── simulate_history_20250503_111707.log
    │   ├── planner_agent_20250529_140950.log
    │   ├── planner_agent_20250529_152330.log
    │   ├── planner_agent_20250530_094950.log
    │   ├── planner_agent_20250530_095048.log
    │   ├── planner_agent_20250530_100118.log
    │   ├── planner_agent_20250530_100640.log
    │   ├── planner_agent_20250530_100828.log
    │   ├── planner_agent_20250530_101048.log
    │   ├── planner_agent_20250530_101119.log
    │   ├── planner_agent_20250530_101216.log
    │   ├── planner_agent_20250530_102116.log
    │   ├── planner_agent_20250530_102249.log
    │   ├── planner_agent_20250530_102528.log
    │   ├── planner_agent_20250530_103157.log
    │   ├── planner_agent_20250530_195346.log
    │   ├── planner_agent_20250530_200344.log
    │   ├── planner_agent_20250530_202313.log
    │   ├── planner_agent_20250530_202606.log
    │   ├── planner_agent_20250530_203117.log
    │   ├── planner_agent_20250531_100838.log
    │   ├── planner_agent_20250531_101430.log
    │   ├── planner_agent_20250531_101544.log
    │   ├── planner_agent_20250531_101858.log
    │   ├── planner_agent_20250531_102303.log
    │   ├── planner_agent_20250531_102643.log
    │   ├── planner_agent_20250531_105346.log
    │   ├── planner_agent_20250531_161705.log
    │   ├── planner_agent_20250531_162103.log
    │   ├── planner_agent_20250531_162228.log
    │   ├── planner_agent_20250531_162548.log
    │   ├── planner_agent_20250531_162837.log
    │   ├── planner_agent_20250531_163730.log
    │   ├── planner_agent_20250531_164027.log
    │   ├── planner_agent_20250531_230057.log
    │   ├── planner_agent_20250531_230525.log
    │   ├── planner_agent_20250531_230924.log
    │   ├── planner_agent_20250531_232240.log
    │   ├── planner_agent_20250531_233528.log
    │   ├── planner_agent_20250531_234018.log
    │   ├── planner_agent_20250531_234136.log
    │   ├── planner_agent_20250601_000739.log
    │   ├── planner_agent_20250601_000900.log
    │   ├── planner_agent_20250601_001033.log
    │   ├── planner_agent_20250601_001120.log
    │   ├── planner_agent_20250601_103146.log
    │   ├── planner_agent_20250601_183211.log
    │   ├── planner_agent_20250601_190912.log
    │   ├── planner_agent_20250601_192245.log
    │   └── rl_ppo
    │       ├── PPO_1
    │       │   └── events.out.tfevents.1747647889.MYPC.39688.0
    │       └── PPO_2
    │           └── events.out.tfevents.1747648726.MYPC.33028.0
    ├── models
    │   ├── __init__.py
    │   ├── envs
    │   │   └── trading_env.py
    │   │       Imports:
    │   │         - core.config.config.settings
    │   │         - core.data_provider.data_provider.fetch_stock_data
    │   │         - gym
    │   │         - gym.spaces
    │   │         - numpy
    │   │         - pandas
    │   │       Class: TradingEnv
    │   │         Methods:
    │   │           - __init__
    │   │           - _get_obs
    │   │           - reset
    │   │           - step
    │   │           - render
    │   ├── joint_policy.py
    │   │   Imports:
    │   │     - joblib
    │   │     - lightgbm
    │   │     - os
    │   │     - pandas
    │   │   Class: JointPolicyModel
    │   │     Methods:
    │   │       - __init__
    │   │       - fit
    │   │       - predict
    │   │       - save
    │   │       - load
    │   ├── meta_strategy_selector.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.data_provider.data_provider.save_data
    │   │     - core.logger.logger.logger
    │   │     - core.model_io.load_model
    │   │     - core.model_io.save_model
    │   │     - itertools
    │   │     - pandas
    │   │     - sklearn.ensemble.RandomForestRegressor
    │   │     - sklearn.metrics.mean_squared_error
    │   │     - sklearn.model_selection.train_test_split
    │   │   Function: load_combined_grid_data
    │   │     Docstring:
    │   │       Load and combine grid search results from all configured CSV paths.
    │   │   Function: train_meta_model
    │   │     Docstring:
    │   │       Train a meta-model to predict strategy performance. Reads combined
    │   │       grid data, applies settings-driven train/test split, trains an RF
    │   │       regressor with settings-backed hyperparams, logs & saves the model and
    │   │       its metadata.
    │   │   Function: suggest_best_parameters
    │   │     Docstring:
    │   │       Given a trained meta-model, enumerate the cartesian product of
    │   │       settings-backed parameter ranges, predict their score, and return the
    │   │       top-N configs as a DataFrame.
    │   ├── ml_dual_model_prediction_sql.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.logger.logger.logger
    │   │     - core.model_io.load_model
    │   │     - core.time_context.time_context.get_simulation_date
    │   │     - pandas
    │   │   Function: predict_dual_model
    │   │     Docstring:
    │   │       Dual‐model prediction pipeline: - Loads fundamentals from `data_path`
    │   │       - Loads feature table from `feature_path` - Runs filter and exit
    │   │       models, returns top_n signals
    │   ├── ml_training_sql.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.data_provider.data_provider.save_data
    │   │     - core.feature_engineering.feature_enricher_multi.enrich_multi_interval_features
    │   │     - core.logger.logger.logger
    │   │     - core.model_io.save_model
    │   │     - pandas
    │   │     - sklearn.ensemble.RandomForestRegressor
    │   │     - sklearn.metrics.mean_squared_error
    │   │     - sklearn.model_selection.train_test_split
    │   │     - sklearn.preprocessing.LabelEncoder
    │   │   Function: merge_intervals
    │   │   Function: train_meta_model
    │   │     Docstring:
    │   │       Train a meta-model (regressor) on combined multi-interval features.
    │   │       Uses settings for split and hyperparams.
    │   ├── predictive_trader
    │   │   ├── RELIANCE_v2_lstm.keras
    │   │   └── RELIANCE_v2_scaler.pkl
    │   ├── rl_policy_20250519_160708.zip
    │   ├── stock_filter_predictor.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.data_provider.data_provider.save_data
    │   │     - core.logger.logger.logger
    │   │     - core.model_io.load_model
    │   │     - pandas
    │   │   Function: run_stock_filter
    │   ├── train_dual_model_sql.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.logger.logger.logger
    │   │     - core.model_io.save_model
    │   │     - optuna
    │   │     - pandas
    │   │     - sklearn.ensemble.RandomForestClassifier
    │   │     - sklearn.ensemble.RandomForestRegressor
    │   │     - sklearn.metrics.accuracy_score
    │   │     - sklearn.metrics.mean_squared_error
    │   │     - sklearn.model_selection.train_test_split
    │   │   Function: _load_training
    │   │   Function: train_dual_model
    │   │   Function: objective_class
    │   │   Function: objective_reg
    │   ├── train_entry_exit_model.py
    │   │   Imports:
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.feature_engineering.feature_enricher_multi.enrich_multi_interval_features
    │   │     - core.logger.logger.logger
    │   │     - core.model_io.save_model
    │   │     - json
    │   │     - pandas
    │   │     - sklearn.ensemble.RandomForestClassifier
    │   │     - sklearn.ensemble.RandomForestRegressor
    │   │     - sklearn.metrics.classification_report
    │   │     - sklearn.model_selection.train_test_split
    │   │     - sklearn.multioutput.MultiOutputRegressor
    │   │     - sklearn.preprocessing.LabelEncoder
    │   │   Function: parse_exit_config
    │   │   Function: train_entry_exit_model
    │   ├── train_exit_model.py
    │   │   Imports:
    │   │     - collections.Counter
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.feature_engineering.feature_enricher_multi.enrich_multi_interval_features
    │   │     - core.logger.logger.logger
    │   │     - core.model_io.save_model
    │   │     - pandas
    │   │     - sklearn.ensemble.RandomForestClassifier
    │   │     - sklearn.metrics.accuracy_score
    │   │     - sklearn.metrics.classification_report
    │   │     - sklearn.model_selection.train_test_split
    │   │   Function: train_exit_model
    │   ├── train_meta_model.py
    │   │   Imports:
    │   │     - core.config.config.get_feature_columns
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.data_provider.data_provider.save_data
    │   │     - core.feature_engineering.feature_enricher_multi.enrich_multi_interval_features
    │   │     - core.logger.logger.logger
    │   │     - core.model_io.save_model
    │   │     - pandas
    │   │     - sklearn.ensemble.RandomForestRegressor
    │   │     - sklearn.metrics.mean_squared_error
    │   │     - sklearn.model_selection.train_test_split
    │   │   Function: train_meta_model
    │   ├── train_param_model.py
    │   │   Imports:
    │   │     - collections.Counter
    │   │     - core.config.config.get_feature_columns
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.logger.logger.logger
    │   │     - core.model_io.save_model
    │   │     - pandas
    │   │     - sklearn.ensemble.RandomForestRegressor
    │   │     - sklearn.metrics.mean_squared_error
    │   │     - sklearn.model_selection.train_test_split
    │   │     - sklearn.multioutput.MultiOutputRegressor
    │   │     - sklearn.preprocessing.LabelEncoder
    │   │   Function: train_param_model
    │   └── train_stock_filter_model.py
    │       Imports:
    │         - core.config.config.settings
    │         - core.data_provider.data_provider.load_data
    │         - core.logger.logger.logger
    │         - core.model_io.save_model
    │         - optuna
    │         - pandas
    │         - sklearn.ensemble.RandomForestClassifier
    │         - sklearn.metrics.accuracy_score
    │         - sklearn.metrics.classification_report
    │         - sklearn.model_selection.train_test_split
    │       Function: train_stock_filter_model
    │         Docstring:
    │           Train a RandomForest-based stock filter model using features.
    │       Function: objective
    ├── monitor
    │   └── feature_status_dashboard.py
    │       Imports:
    │         - os
    │         - redis
    │         - time
    │       Function: check_status
    ├── odin_banner.txt
    ├── paper_trader.py
    │   Imports:
    │     - core.logger.logger.logger
    │     - datetime.datetime
    │     - os
    │     - pandas
    │     - yfinance
    │   Function: load_recommendations
    │   Function: load_open_positions
    │   Function: load_today_price
    │   Function: enter_trades
    │   Function: check_exit_condition
    │   Function: exit_trades
    │   Function: log_trades
    │   Function: main
    ├── policy_chooser_deploy.yaml
    ├── ppo_buffers
    ├── prefect.yaml
    ├── project_data
    │   ├── archive
    │   ├── logs
    │   ├── meta
    │   ├── models
    │   ├── predictions
    │   ├── processed
    │   ├── raw
    │   ├── results
    │   │   📄 Skipped 4 data files (.csv, .json, .pyc)
    │   │   └── history
    │   ├── secrets
    │   └── trading_system.db
    ├── project_status.md
    ├── project_summary.txt
    ├── readme.md
    ├── redis_worker
    │   ├── Dockerfile
    │   ├── enqueue_jobs.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - db.postgres_manager.get_all_symbols
    │   │     - os
    │   │     - redis
    │   ├── logs
    │   │   ├── planner_agent_20250530_022226.log
    │   │   ├── planner_agent_20250530_022235.log
    │   │   ├── planner_agent_20250530_022245.log
    │   │   ├── planner_agent_20250530_023351.log
    │   │   ├── planner_agent_20250530_023401.log
    │   │   └── planner_agent_20250530_023410.log
    │   ├── redis_utils.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - core.logger.logger.logger
    │   │     - os
    │   │     - redis
    │   │     - time
    │   │   Function: enqueue_feature_backfill
    │   │     Docstring:
    │   │       Enqueue a feature backfill job for a specific symbol and interval.
    │   │       Returns True if enqueued, False if already in progress or done.
    │   │   Function: wait_for_feature_ready
    │   │     Docstring:
    │   │       Block until the feature job finishes or timeout hits. Returns: 'done',
    │   │       'error: <msg>', or 'timeout'
    │   │   Function: enqueue_feature_backfill
    │   │     Docstring:
    │   │       Queue a symbol for feature backfill unless already enqueued.
    │   └── worker.py
    │       Imports:
    │         - core.config.config.settings
    │         - core.feature_engineering.feature_provider.fetch_features
    │         - core.logger.logger.logger
    │         - os
    │         - redis
    │         - time
    │         - traceback
    ├── report_generator.py
    │   Imports:
    │     - core.logger.logger.logger
    │     - datetime.datetime
    │     - matplotlib.pyplot
    │     - os
    │     - pandas
    │     - yfinance
    │   Function: load_data
    │   Function: analyze_trades
    │   Function: fetch_current_price
    │   Function: analyze_open_positions
    │   Function: main
    ├── reports
    │   ├── daily_snapshot.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.logger.logger.logger
    │   │     - datetime.datetime
    │   │     - datetime.timedelta
    │   │     - pandas
    │   │   Function: compute_snapshot
    │   └── dashboards
    │       ├── system_dashboard.py
    │       │   Imports:
    │       │     - datetime.datetime
    │       │     - db.postgres_manager.run_query
    │       │     - logging
    │       │     - pandas
    │       │     - streamlit
    │       │   Function: load_agent_status
    │       │   Function: load_today_trades
    │       │   Function: load_training_data_count
    │       │   Function: load_retrained_models
    │       │   Function: load_feedback_status
    │       └── system_dashboard_backup.py
    │           Imports:
    │             - datetime.datetime
    │             - datetime.timedelta
    │             - db.postgres_manager.run_query
    │             - pandas
    │             - reports.weekly_snapshot.compute_snapshot
    │             - streamlit
    │           Function: load_system_log
    │           Function: load_trade_summary
    ├── requirements-dev.txt
    ├── requirements.txt
    ├── results
    ├── reward_updater_deploy.yaml
    ├── rl
    │   ├── buffers
    │   │   └── ppo_buffers
    │   ├── envs
    │   │   ├── offline_env.py
    │   │   │   Imports:
    │   │   │     - gymnasium.Env
    │   │   │     - gymnasium.spaces.Box
    │   │   │     - gymnasium.spaces.Discrete
    │   │   │     - hashlib
    │   │   │     - logging
    │   │   │     - numpy
    │   │   │     - pandas
    │   │   │   Class: OfflineEnv
    │   │   │     Docstring:
    │   │   │       An offline environment that replays stored transitions from a replay
    │   │   │       buffer. Each row contains: state, action, reward, next_state, and
    │   │   │       done. Adds inferred next_state, done flag, episode_id, step_count, and
    │   │   │       metadata. Applies reward shaping based on metadata and logs shaped vs
    │   │   │       raw rewards.
    │   │   │     Methods:
    │   │   │       - __init__
    │   │   │       - _prepare_episodes
    │   │   │       - reset
    │   │   │       - _calculate_shaped_reward
    │   │   │       - step
    │   │   └── trading_env.py
    │   │       Imports:
    │   │         - core.data_provider.data_provider.fetch_stock_data
    │   │         - core.feature_engineering.feature_enricher_multi.enrich_multi_interval_features
    │   │         - core.logger.logger.logger
    │   │         - core.model_io.load_latest_model
    │   │         - core.model_io.load_model
    │   │         - core.model_io.save_model
    │   │         - core.predict.rl_predictor.TradingEnv
    │   │         - core.predict.rl_predictor.load_policy
    │   │         - core.predict.rl_predictor.load_rl_frame
    │   │         - core.time_context.time_context.get_simulation_date
    │   │         - datetime.datetime
    │   │         - gymnasium
    │   │         - gymnasium.spaces
    │   │         - numpy
    │   │         - stable_baselines3.PPO
    │   │         - stable_baselines3.common.vec_env.DummyVecEnv
    │   │       Class: TradingEnv
    │   │         Docstring:
    │   │           A trading environment supporting long and short positions with reward
    │   │           shaping, drawdown penalties, max holding logic, and episodic control.
    │   │         Methods:
    │   │           - __init__
    │   │           - _get_obs
    │   │           - reset
    │   │           - _calculate_reward
    │   │           - step
    │   │       Function: save_rl_model
    │   │       Function: predict_with_fallback
    │   ├── policies
    │   ├── replay_buffer.py
    │   │   Imports:
    │   │     - datetime.datetime
    │   │     - datetime.timedelta
    │   │     - os
    │   │     - pandas
    │   │   Class: ReplayBuffer
    │   │     Methods:
    │   │       - __init__
    │   │       - add_episode
    │   │       - sample
    │   │       - clear_old
    │   │       - __len__
    │   ├── rl_finetune.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - core.logger.logger.logger
    │   │     - core.model_io.load_latest_model
    │   │     - core.model_io.load_model
    │   │     - core.model_io.save_model
    │   │     - datetime.datetime
    │   │     - db.replay_buffer_sql.load_replay_episodes
    │   │     - numpy
    │   │     - os
    │   │     - rl.envs.trading_env.TradingEnv
    │   │     - stable_baselines3.PPO
    │   │     - stable_baselines3.common.vec_env.DummyVecEnv
    │   │   Class: OfflineEnv
    │   │     Methods:
    │   │       - __init__
    │   │       - reset
    │   │       - step
    │   │   Function: finetune_rl
    │   ├── train_rl_agent.py
    │   │   Imports:
    │   │     - argparse
    │   │     - core.config.config.settings
    │   │     - core.logger.logger.logger
    │   │     - core.model_io.save_model
    │   │     - core.predict.rl_predictor.load_rl_frame
    │   │     - datetime.datetime
    │   │     - os
    │   │     - pandas
    │   │     - rl.envs.trading_env.TradingEnv
    │   │     - stable_baselines3.PPO
    │   │     - stable_baselines3.common.vec_env.DummyVecEnv
    │   │   Function: get_symbols
    │   │   Function: make_env
    │   │   Function: main
    │   │   Function: _env
    │   ├── train_rl_intraday.py
    │   │   Imports:
    │   │     - rl.train_rl_agent.main
    │   │     - sys
    │   └── utils.py
    ├── scripts
    │   ├── __archive__
    │   │   ├── db_manager.py
    │   │   │   Imports:
    │   │   │     - config.paths.PATHS
    │   │   │     - core.logger.logger.logger
    │   │   │     - pandas
    │   │   │     - sqlite3
    │   │   │     - time
    │   │   │   Function: get_connection
    │   │   │     Docstring:
    │   │   │       Block until connection is possible and WAL is enabled.
    │   │   │   Function: insert_dataframe
    │   │   │   Function: read_table
    │   │   │   Function: run_query
    │   │   │   Function: list_tables
    │   │   │   Function: execute_raw_sql
    │   │   │   Function: enable_wal_mode
    │   │   ├── execution_agent.py
    │   │   │   Imports:
    │   │   │     - config.paths.PATHS
    │   │   │     - core.data_provider.data_provider.load_data
    │   │   │     - core.data_provider.data_provider.save_data
    │   │   │     - core.logger.logger.logger
    │   │   │     - datetime.datetime
    │   │   │     - os
    │   │   │     - pandas
    │   │   │     - time
    │   │   │     - utils.file_io.load_dataframe
    │   │   │     - utils.file_io.save_dataframe
    │   │   │     - yfinance
    │   │   │   Class: ExecutionAgent
    │   │   │     Methods:
    │   │   │       - __init__
    │   │   │       - load_recommendations
    │   │   │       - load_open_positions
    │   │   │       - load_today_price
    │   │   │       - check_exit_condition
    │   │   │       - log_trades
    │   │   │       - enter_trades
    │   │   │       - exit_trades
    │   │   │       - run
    │   │   ├── historical_data
    │   │   │   📄 Skipped 666 data files (.csv, .json, .pyc)
    │   │   ├── planner_agent.py
    │   │   │   Imports:
    │   │   │     - agents.execution.execution_agent_sql.ExecutionAgent
    │   │   │     - agents.memory.feedback_loop.update_training_data
    │   │   │     - agents.memory.memory_agent.MemoryAgent
    │   │   │     - agents.strategy.strategy_agent.StrategyAgent
    │   │   │     - config.paths.PATHS
    │   │   │     - core.data_provider.data_provider.load_data
    │   │   │     - core.data_provider.data_provider.save_data
    │   │   │     - core.logger.logger.logger
    │   │   │     - datetime.datetime
    │   │   │     - fundamentals.fundamental_data_extractor
    │   │   │     - models.stock_filter_predictor.run_stock_filter
    │   │   │     - os
    │   │   │     - pandas
    │   │   │     - stock_selecter.auto_filter_selector.auto_select_filter
    │   │   │     - utils.file_io.save_dataframe
    │   │   │   Class: PlannerAgent
    │   │   │     Methods:
    │   │   │       - __init__
    │   │   │       - run_weekly_routine
    │   │   └── train_dual_model.py
    │   │       Imports:
    │   │         - config.paths.PATHS
    │   │         - core.logger.logger.logger
    │   │         - core.model_io.load_model
    │   │         - core.model_io.save_model
    │   │         - json
    │   │         - os
    │   │         - pandas
    │   │         - pickle
    │   │         - sklearn.ensemble.RandomForestClassifier
    │   │         - sklearn.ensemble.RandomForestRegressor
    │   │         - sklearn.metrics.classification_report
    │   │         - sklearn.metrics.mean_squared_error
    │   │         - sklearn.model_selection.train_test_split
    │   │         - sklearn.preprocessing.LabelEncoder
    │   │         - utils.file_io.load_dataframe
    │   │       Function: train_dual_models
    │   ├── check_data_completeness.py
    │   │   Imports:
    │   │     - core.skiplist.skiplist.get_skiplist
    │   ├── check_db_orm_match.py
    │   │   Imports:
    │   │     - db.models.Base
    │   │     - os
    │   │     - sqlalchemy.create_engine
    │   │     - sqlalchemy.inspect
    │   │   Function: check_schema
    │   ├── enqueue_backfill_jobs.py
    │   │   Imports:
    │   │     - db.postgres_manager.get_all_symbols
    │   │     - json
    │   │     - os
    │   │     - redis
    │   ├── fetch_instruments.py
    │   │   Imports:
    │   │     - integrations.zerodha_client.get_kite
    │   │     - pandas
    │   ├── fix_logger_shadowing.py
    │   │   Imports:
    │   │     - os
    │   │     - re
    │   │   Function: process_file
    │   │   Function: scan_project
    │   ├── generate_token.py
    │   │   Imports:
    │   │     - dotenv.load_dotenv
    │   │     - dotenv.set_key
    │   │     - json
    │   │     - kiteconnect.KiteConnect
    │   │     - os
    │   │     - webbrowser
    │   ├── init_db.py
    │   │   Imports:
    │   │     - db.db.engine
    │   │     - db.models.Base
    │   ├── load_backup_fundamentals.py
    │   │   Imports:
    │   │     - core.data_provider.data_provider.save_data
    │   │     - pandas
    │   ├── prefill_price_history.py
    │   │   Imports:
    │   │     - core.data_provider.data_provider.fetch_stock_data
    │   │     - core.data_provider.data_provider.save_data
    │   │     - core.logger.logger.logger
    │   │     - datetime.datetime
    │   │     - integrations.zerodha_fetcher.INTERVAL_LIMIT_DAYS
    │   │     - pandas
    │   │     - pathlib.Path
    │   │   Function: load_symbols
    │   │   Function: prefill_all
    │   ├── reset_system.py
    │   │   Imports:
    │   │     - argparse
    │   │     - core.logger.logger.logger
    │   │     - db.db_router.run_query
    │   │     - os
    │   │     - pathlib.Path
    │   │     - shutil
    │   │     - sys
    │   │   Function: drop_partitioned_feature_tables
    │   │   Function: delete_model_files
    │   │   Function: clear_cache_dirs
    │   │   Function: main
    │   ├── seed_training_data.py
    │   │   Imports:
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.data_provider.data_provider.save_data
    │   │     - core.logger.logger.logger
    │   │     - pandas
    │   │   Function: seed_training_data
    │   ├── update_prices.py
    │   │   Imports:
    │   │     - core.data_provider.data_provider.cache_price
    │   │     - core.price_service.get_prices
    │   │     - core.time_context.time_context.get_simulation_date
    │   │     - db.postgres_manager.get_all_symbols
    │   └── validate_duckdb_feature_coverage.py
    │       Imports:
    │         - core.feature_store.feature_store.get_cached_features
    │         - core.logger.logger.logger
    │         - datetime.datetime
    │         - datetime.timedelta
    │         - pandas
    │       Function: get_recent_dates
    │       Function: validate_duckdb_cache
    ├── services
    │   └── exit_policy_evaluator.py
    │       Imports:
    │         - core.feature_engineering.feature_enricher_multi.enrich_multi_interval_features
    │         - core.logger.logger.logger
    │         - core.model_io.load_model
    │         - core.time_context.time_context.get_simulation_date
    │         - numpy
    │         - pandas
    │         - pydantic.BaseModel
    │         - traceback
    │         - typing.Literal
    │         - typing.Optional
    │       Class: ExitRule
    │       Function: get_exit_probability
    │         Docstring:
    │           Return probability that the position should be exited (1 = exit).
    │       Function: should_exit_model_based
    ├── stock_features_15m.sql
    ├── stock_features_60m.sql
    ├── stock_selecter
    │   📄 Skipped 2 data files (.csv, .json, .pyc)
    │   ├── auto_filter_selector.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.logger.logger.logger
    │   │     - core.time_context.time_context.get_simulation_date
    │   │     - datetime.datetime
    │   │     - os
    │   │     - pandas
    │   │     - stock_selecter.fallback_technical_filter.run_technical_filter
    │   │     - stock_selecter.stock_screener.run_stock_filter
    │   │   Function: auto_select_filter
    │   ├── fallback_technical_filter.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.data_provider.data_provider.save_data
    │   │     - core.logger.logger.logger
    │   │     - core.time_context.time_context.get_simulation_date
    │   │     - datetime.datetime
    │   │     - pandas
    │   │   Function: run_technical_filter
    │   └── stock_screener.py
    │       Imports:
    │         - core.config.config.settings
    │         - core.data_provider.data_provider.load_data
    │         - core.data_provider.data_provider.save_data
    │         - core.logger.logger.logger
    │         - core.time_context.time_context.get_simulation_date
    │         - datetime.datetime
    │         - pandas
    │       Function: filter_growth_stocks
    │       Function: filter_value_stocks
    │       Function: filter_momentum_stocks
    │       Function: filter_defensive_stocks
    │       Function: filter_small_cap_gems
    │       Function: filter_high_volatility_stocks
    │       Function: run_stock_filter
    │         Docstring:
    │           1) Load fundamentals 2) Apply filter_name 3) Persist only 'stock' (+
    │           timestamp) back to SQL
    │       Function: get_stock_list
    │         Docstring:
    │           Read back the ML-selected table for downstream use.
    ├── tests
    │   ├── __init__.py
    │   ├── conftest.py
    │   │   Imports:
    │   │     - pandas
    │   │     - pytest
    │   │   Function: dummy_training_data
    │   │     Docstring:
    │   │       Very small fixture DataFrame for unit tests.
    │   ├── test_data_audit.py
    │   │   Imports:
    │   │     - analysis.data_audit.main
    │   │     - core.data.data_provider
    │   │     - json
    │   │     - pandas
    │   │     - pathlib.Path
    │   │     - sys
    │   │   Function: test_data_audit_threshold_behavior
    │   │   Function: mock_load_data
    │   ├── test_data_checks.py
    │   │   Imports:
    │   │     - core.validation.data_checks.check_missing
    │   │     - core.validation.data_checks.class_balance
    │   │     - core.validation.data_checks.detect_outliers
    │   │     - numpy
    │   │     - pandas
    │   │   Function: test_check_missing
    │   │   Function: test_class_balance
    │   │   Function: test_detect_outliers_zscore
    │   │   Function: test_detect_outliers_iqr
    │   │   Function: test_detect_outliers_zscore
    │   ├── test_feature_pipeline.py
    │   │   Imports:
    │   │     - analysis.feature_pipeline.check_temporal_alignment
    │   │     - analysis.feature_pipeline.detect_high_correlation
    │   │     - numpy
    │   │     - pandas
    │   │     - pytest
    │   │   Function: test_temporal_alignment_pass
    │   │   Function: test_temporal_alignment_fail
    │   │   Function: test_high_correlation_detection
    │   ├── test_feedback_loop.py
    │   │   Imports:
    │   │     - analysis.feedback_loop.main
    │   │     - core.data.data_provider
    │   │     - pandas
    │   │     - pytest
    │   │   Function: dummy_feedback_data
    │   │   Function: test_feedback_loop_kpis
    │   └── test_model_health.py
    │       Imports:
    │         - analysis.model_health
    │         - core.data.data_provider
    │         - os
    │         - pandas
    │         - pytest
    │       Function: dummy_model_metadata
    │       Function: test_model_drift_detection
    ├── tracking_progress.md
    ├── tracking_progress_old.md
    ├── train_joint_policy_flow
    ├── train_rl_policy_flow
    ├── train_strategy_selector.py
    │   Imports:
    │     - core.logger.logger.logger
    │     - pandas
    │     - pickle
    │     - sklearn.ensemble.RandomForestRegressor
    │     - sklearn.model_selection.train_test_split
    │     - sklearn.multioutput.MultiOutputRegressor
    │   Function: train_strategy_selector
    ├── training
    │   ├── run_ppo_training.py
    │   │   Imports:
    │   │     - core.rl.gym_env.ODINTradingEnv
    │   │     - core.rl.ppo_trainer.PPOTrainer
    │   │     - core.rl.sql_env.ODINSQLTradingEnv
    │   │     - time
    │   ├── train_joint_policy.py
    │   │   Imports:
    │   │     - core.config.config.settings
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.feature_engineering.feature_provider.fetch_features
    │   │     - core.logger.logger.logger
    │   │     - datetime.timedelta
    │   │     - models.joint_policy.JointPolicyModel
    │   │     - pandas
    │   │   Function: load_training_data
    │   │   Function: sample_negative_examples
    │   │   Function: fetch_feature_data
    │   │   Function: train_model
    │   │   Function: main
    │   └── train_sb3_ppo.py
    │       Imports:
    │         - core.rl.sql_env.ODINSQLTradingEnv
    │         - os
    │         - stable_baselines3.PPO
    │         - stable_baselines3.common.monitor.Monitor
    │         - stable_baselines3.common.vec_env.DummyVecEnv
    │       Function: make_env
    ├── utils
    │   ├── file_io.py
    │   │   Imports:
    │   │     - core.logger.logger.logger
    │   │     - os
    │   │     - pandas
    │   │   Function: load_dataframe
    │   │   Function: save_dataframe
    │   ├── precheck_features.py
    │   │   Imports:
    │   │     - config.paths.PATHS
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.feature_generator.generate_features
    │   │     - core.logger.logger.logger
    │   │     - core.model_io.load_model
    │   │     - datetime.datetime
    │   │     - json
    │   │     - os
    │   │     - pandas
    │   │   Function: get_model_features
    │   │   Function: is_feature_usable
    │   │   Function: prefilter_valid_stocks
    │   ├── progress_logger.py
    │   │   Imports:
    │   │     - datetime.datetime
    │   │     - sqlite3
    │   │   Function: log_model_progress
    │   ├── skiplist_manager.py
    │   │   Imports:
    │   │     - db.db_router.run_query
    │   │     - json
    │   │     - os
    │   │   Function: load_skiplist
    │   │   Function: add_to_skiplist
    │   │   Function: load_failed_precheck
    │   │   Function: add_failed_precheck
    │   ├── sql_utils.py
    │   │   Imports:
    │   │     - config.sql_tables.SQL_TABLES
    │   │   Function: is_sql_table
    │   ├── stock_health_precheck.py
    │   │   Imports:
    │   │     - core.data_provider.data_provider.load_data
    │   │     - core.logger.logger.logger
    │   │   Function: is_stock_tradeable
    │   ├── stock_precheck.py
    │   │   Imports:
    │   │     - config.paths.PATHS
    │   │     - core.feature_generator.generate_features
    │   │     - core.logger.logger.logger
    │   │     - core.model_io.load_model
    │   │   Function: is_feature_ready
    │   │   Function: filter_valid_stocks
    │   ├── technical_indicators.py
    │   │   Imports:
    │   │     - pandas
    │   │   Function: compute_sma
    │   │   Function: compute_rsi
    │   └── time_utils.py
    │       Imports:
    │         - pandas
    │         - pytz.timezone
    │       Function: to_naive_utc
    │       Function: to_ist
    │         Docstring:
    │           Converts datetime column to IST (timezone-aware).
    │       Function: localize_if_needed
    └── workers
        ├── backfill_feature_worker.py
        │   Imports:
        │     - core.feature_engineering.feature_provider.fetch_features
        │     - core.logger.logger.logger
        │     - json
        │     - os
        │     - redis
        │     - time
        └── missed_trade_logger.py
            Function: log_missed_trades
